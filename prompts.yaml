chunker:
  section_labeling: |
    You are given a list of section titles from a single research paper. Categorize each title into one of the following:

    ["Abstract", "Introduction", "Problem Definition", "Methodology", "Related Work", "Experiment"]

    If a title does not clearly fit any category, assign it to the most likely one based on typical academic paper structure. Multiple titles can belong to the same category. But one title should not belong to multiple categories.

    Please output only the raw JSON object without any explanation or formatting ‚Äî do not wrap the output in triple backticks or add a language label. Format: 
    {
      "Abstract": [titles assigned to Abstract],
      "Introduction": [titles assigned to Introduction],
      "Problem Definition": [titles assigned to Problem Definition],
      "Methodology": [titles assigned to Methodology],
      "Related Work": [titles assigned to Related Work],
      "Experiment": [titles assigned to Experiment],
      "Conclusion": [titles assigned to Conclusion],
      "References": [titles assigned to References],
      "Acknowledgement": [titles assigned to Acknowledgement],
      "Appendix": [titles assigned to Appendix]
    }

    Input:
    [Title List]
    Output:


taxonomy_generator:
  task_taxonomy: 
    extract_problem_definition: |
      You are acting as a **research assistant** tasked with analyzing a research paper to extract its **core research problem** in a **structured**, **methodology-agnostic** format.

      Your objective is to **identify or infer the problem definition** and decompose it into precise components that describe **what the problem is**, **without referencing how it is solved**. Do not include any mention of algorithms, models, frameworks, training strategies, or implementation details.

      If the paper uses shorthand (e.g., acronyms, variables, or mathematical notation), refer to the preliminaries or notation sections to rewrite the problem in a **clear and unambiguous** manner.

      ---

      ### ‚úÖ Output Format

      ```yaml
      paper_id: "<Title of the paper or name of the proposed method>"

      problem_formulation:
        simple_description: >
          "<One-sentence summary of the problem, or `None` if not found.>"

        formal_definition:
          input: >
            "<Describe the input, including its type, structure, and properties. Mention hardware constraints only if they are explicitly part of the problem setting‚Äîdo NOT infer hardware requirements from experimental setups.>"
          output: >
            "<Describe the desired output, including type, structure, and expected characteristics.>"
      ```

      ---

      ### üß≠ Step-by-Step Instructions

      #### üîπ Step 1: Generate `simple_description`

      Create a concise, self-contained summary of the problem using this template:

      > **"Given <input>, the goal is to obtain <output> by achieving <objective>."**

      Follow this order when searching for the problem statement:

      1. Dedicated **Problem Definition** section
      2. **Introduction**
      3. **Abstract**
      4. Relevant parts of the **Methodology** *(only for high-level task description‚Äînot implementation details)*
      5. Any other section as necessary

      > If no coherent one-sentence summary can be extracted, return:

      ```yaml
      simple_description: None
      ```

      > ‚úÖ When a paper describes multiple related problems, prioritize the **primary** or **most general** problem formulation unless others are clearly independent.

      ---

      #### üîπ Step 2: Generate `formal_definition`

      Decompose the problem into the following structured components:

      | Field      | What to Describe                                                                                                                                                                                                                                                                         |
      | ---------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
      | **input**  | The data or contextual information provided to the system. Include type, format, and any explicitly stated constraints (e.g., memory, disk). **Do not treat the hardware used in experimental settings as input constraints unless they are explicitly part of the problem definition.** |
      | **output** | The expected result, product, or prediction. Include type and structure. Do not include how it is computed.                                                                                                                                                                              |

      > Leave any field blank (`""`) if it cannot be inferred from the paper.

      ---

      ### üö´ Do Not Include:

      * Specific methods, algorithms, architectures, or procedural details
      * Training objectives, loss functions, or optimization strategies
      * System or model names
      * Hardware specifications from experiments (e.g., GPUs, clusters), **unless explicitly part of the problem setting**

      ---

      ### ‚ö†Ô∏è Common Pitfalls to Avoid

      | Case                                               | Guideline                                                                                                                                                  |
      | -------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |
      | **Hardware in experiments**                        | Never assume experimental hardware is part of the problem input unless **explicitly described** (e.g., ‚Äúthe task must run on edge devices with ‚â§2GB RAM‚Äù). |
      | **Vague or entangled problem-method descriptions** | Isolate the **task definition** only. If it's mixed with solution details, extract only the input‚Äìoutput‚Äìgoal relationship.                                |
      | **Multiple sub-problems**                          | Focus on the **primary problem** or provide a clearly separated list if multiple are independently defined.                                                |
      | **No clear problem statement**                     | Use context from preliminaries, task descriptions, or dataset definitions to infer a possible formulation. If still ambiguous, return `"None"` as needed.  |

      Below is the paper content:
      [Paper Content]

    aspect_classification: |
      You are given a list of problem definitions extracted from a collection of computer science research papers. Each definition includes structured aspects such as:

      * **Input**
      * **Output**

      ---

      ## ‚úÖ Task: Aspect-Wise Classification Process

      Focus on the following two aspects:

      * **Input**
      * **Output**

      For **each aspect**, process its corresponding content independently and repeat the following steps:

      ---

      ### üî• Step 1: Extract Key Entities

      Iterate over each paper. From the content of the current aspect:

      * Identify the main research-related entities (key concepts) that **describe the authors‚Äô formulation of this aspect** and are **explicitly emphasized in `problem_formulation` as central to the problem definition**.
      * If `problem_formulation` lacks sufficient information, refer to the corresponding structured field (**input**, **output**) for clarification.

      Focus on extracting noun phrases that match the aspect‚Äôs definition:

      * **Input**: Describe the input, including its type, structure, and properties. Mention hardware constraints only if they are explicitly part of the problem setting‚Äîdo NOT infer hardware requirements from experimental setups.
      * **Output**: Describe the desired output, including type, structure, and expected characteristics.

      ---

      ### üî• Step 2: Group Entities Within Sublists

      Group entities within the same paper and aspect into **local entity groups**. These groups reflect strong correlations between entities (they appear together in the same problem definition). Build connections among entities in each group to capture their co-occurrence relationships.

      ---

      ### üî• Step 3: Align and Merge Entities Across Sublists

      * **Identify Related Entities:** Merge entities across papers if they are exact matches, semantically equivalent, or containment relationships.
      * **Merge into Unified Nodes:** Example: {"user-item matrix", "rating matrix"} ‚Üí `Interaction Matrix`.
      * **Build Global Entity Groups:** Connected components of unified nodes form candidate classes.

      ---

      ### üî• Step 4: Refine Classes and Classify Papers

      1. **Provide Class Explanations:** For each resulting class, provide a short description of its scope and relevance.
      2. **Drop or Merge Small Classes:** Merge or drop classes with <2 papers.
      3. **Align Class Names:** Use formal research terminology.
      4. **Assign Papers:** Assign each paper to one or more classes per aspect.

      ---

      ### üî• Step 5: Identify Unassigned or Misaligned Papers

      * Detect **unassigned papers** (entities extracted but no class assignment).
      * Detect **misalignments** (entities poorly matched to class descriptions).
      * Suggest corrections (reassignment or new class).

      ---

      ### üî• Step 6: Implement Corrections

      * For each **unassigned or misaligned paper** identified in Step 5, update the classification by:

        * Assigning it to the most appropriate existing class if suggested.
        * Or creating a new class if no suitable class exists.
      * Ensure that the **final classification output incorporates these corrections directly**, so that all papers have appropriate assignments.

      ---

      ## üìã Output Format

      Return the results **strictly in valid JSON format** with the following structure:

      ```json
      {
        "input_classification": {
          "classes": [
            {
              "class_name": "User-Item Matrix",
              "class_description": "Matrix representation of user-item interactions, commonly used in recommendation tasks.",
              "papers": ["Paper A", "Paper C"]
            },
            {
              "class_name": "Knowledge Graph",
              "class_description": "Graph-based structured input capturing relational facts.",
              "papers": ["Paper B", "Paper F"]
            },
            {
              "class_name": "Temporal Sequence Data",
              "class_description": "Sequential data used for modeling time-dependent behaviors.",
              "papers": ["Paper G"]   // Correction applied here
            }
          ]
        },
        "output_classification": {
          "classes": [
            {
              "class_name": "Hash Codes",
              "class_description": "Compact binary representations of input data used for efficient retrieval.",
              "papers": ["Paper A", "Paper D"]
            },
            {
              "class_name": "Ranked List",
              "class_description": "Ordered set of relevant results returned for a given query.",
              "papers": ["Paper B", "Paper E"]
            }
          ]
        }
      }
      ```
      Below is the problem definition list:
      [Problem Definitions]

    taxonomy_generation: |
      You are an expert research taxonomist. You are given one **JSON object**, containing the classification result of the problem aspects:

      * **Input**: The nature or structure of data the research problem takes as input
      * **Output**: The expected result, format, or structure produced by the method.

      ---

      ### üì• Input Format

      Each JSON object contains an array of class entries. Each entry has the following fields:

      ```json
      {
        "class_name": "string",
        "class_description": "string",
        "supporting_papers": ["PaperA", "PaperB", ...]
      }
      ```

      Below is the classification result:
      [Classification Result]

      ---

      ## ‚úÖ Goal

      Construct a **single hierarchical taxonomy of meaningful research tasks**, where each task is defined by a combination of **Input** and **Output** classes.

      Each node in the taxonomy must represent a **specific, expressive, and well-scoped research task**, not just a data structure or format.

      ---

      ### üî• Step 1: Normalize and Refine Class Labels

      1. **Normalize Class Names:** Use standard academic terminology where possible. Resolve informal, ambiguous, or overly generic names using their class descriptions and example papers.
      2. **Merge Equivalent or Contained Classes:** If two classes are synonyms or exhibit strict containment (e.g., ‚Äúuser-item matrix‚Äù ‚äÜ ‚Äúinteraction matrix‚Äù), merge them.
      3. **Drop or Collapse Weak Classes:** Drop classes with too few or overly vague supporting papers unless they can be merged into broader categories.

      **Output:** Refined JSON list of input and output classes.

      ---

      ### üî• Step 2: Form Meaningful Task Nodes by Input‚ÄìOutput Pairing

      1. **Pair Input and Output Classes:** For every (Input, Output) pair, check if it defines a **coherent, meaningful research task**.
      2. **Keep only valid task nodes** that meet all three criteria:

        * The pair appears in at least **2 different papers**
        * The pairing reflects a **common and recognizable research objective**
        * The task name can be made **expressive** (not just ‚ÄúMatrix ‚Üí Vector‚Äù).
      3. **Name Each Task:**
        Use the format:

        ```
        TASK:L{level}:{CANONICAL_NAME}
        ```

      ---

      ### üî• Step 3: Build a Hierarchy over the Tasks

      1. **Group Similar Tasks:**

        * Parent-child relationships based on task granularity and generalization.
        * Example:

          * Parent: `KNOWLEDGE_GRAPH_TASKS`

            * Child: `KNOWLEDGE_GRAPH_EMBEDDING`
            * Child: `KNOWLEDGE_GRAPH_COMPLETION`

      2. **Hierarchy Rules:**

        * Use only **IS-A** relationships.
        * Construct a **tree** (no DAGs or cycles).
        * Root node: `ROOT`.

      ---

      ## üìã Output Format (JSON Only)

      Return the taxonomy strictly as **valid JSON**. Each node must have:

      * `task_id`: Unique ID in the format `TASK:L{level}:{CANONICAL_NAME}`
      * `task_name`: Expressive descriptive name
      * `input_class`: Input class name
      * `output_class`: Output class name
      * `explanation`: 1‚Äì2 sentence explanation of the task
      * `papers`: List of supporting papers
      * `children`: Array of child task nodes

      Example:

      ```json
      {
        "taxonomy": {
          "task_id": "ROOT",
          "task_name": "ROOT",
          "children": [
            {
              "task_id": "TASK:L1:KNOWLEDGE_GRAPH_COMPLETION",
              "task_name": "Knowledge Graph Completion",
              "input_class": "Knowledge Graph",
              "output_class": "Completed Triples",
              "explanation": "Predict missing edges in a relational graph based on observed triples.",
              "papers": ["PaperA", "PaperD"],
              "children": []
            },
            {
              "task_id": "TASK:L1:HASH_CODE_GENERATION_FOR_RETRIEVAL",
              "task_name": "Hash Code Generation for Retrieval",
              "input_class": "User-Item Interaction Matrix",
              "output_class": "Hash Codes",
              "explanation": "Generate compact binary representations for fast retrieval in recommendation settings.",
              "papers": ["PaperB", "PaperF"],
              "children": []
            }
          ]
        }
      }
      ```

      * Ensure the JSON is **syntactically valid**.
      * Do not output Markdown, tables, or text outside the JSON block.

      ---

      
  


