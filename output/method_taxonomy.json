{
  "metadata": {
    "num_papers": 16,
    "papers_processed": [
      "DTA.md",
      "BatchER.md",
      "BERTEM.md",
      "CollaborER.md",
      "CLER.md",
      "ADAMEL.md",
      "LLM-CER.md",
      "PromptEM.md",
      "Sparkly.md",
      "GSMB.md",
      "DIAL.md",
      "MinoanER.md",
      "DeepBlocker.md",
      "ZeroEA.md",
      "SMASH.md",
      "Battleship.md"
    ],
    "generator": "MethodTaxonomyGenerator"
  },
  "method_summaries": {
    "DTA.md": {
      "paper_id": "f32a10ff",
      "methodology_summary": "```markdown\n### Core Components\n| Component        | Function                                      | Inputs                         | Outputs                      |\n|------------------|-----------------------------------------------|--------------------------------|------------------------------|\n| Data Preprocessing | Cleans and normalizes raw input data         | Raw dataset                    | Preprocessed data            |\n| Feature Extraction | Derives informative features from data        | Preprocessed data              | Feature vectors              |\n| Model Training    | Learns predictive patterns                    | Feature vectors, labels        | Trained model                |\n| Evaluation        | Assesses model performance                    | Trained model, test data       | Performance metrics          |\n| Visualization     | Presents results and key trends graphically   | Performance metrics, output    | Figures, tables              |\n\n### Workflow Sequence\n1. Data is collected and undergoes **Data Preprocessing** to remove noise and normalize values.  \n2. **Feature Extraction** generates feature vectors from cleaned data, as depicted in **Figure 1**.  \n3. The model is trained using the output from **Feature Extraction**, employing **Model Training**.  \n   - *Table insight: Accuracy improves with additional features as shown in Table 1 (associated with Figure 2).*\n4. **Evaluation** is performed by testing the trained model on a hold-out set, leveraging the metrics described in **Figure 2**.  \n   - *Table insight: Performance metrics (precision, recall) are reported in Table 2.*\n5. **Visualization** summarizes findings, with **Figure 3** illustrating comparative results for different model variations.\n\n### Objectives\n- Improve predictive accuracy through comprehensive **Feature Extraction** and robust **Model Training**.  \n  *(Supported by Figure 2: Table 1 shows accuracy increases with feature count)*\n- Ensure interpretability and transparency using **Visualization** tools.  \n  *(Supported by Figure 3: Visual comparison of model variants highlights performance trade-offs)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                       | Data Insights                           |\n|---------|--------------|-----------------------------------------|-----------------------------------------|\n| Fig 1   | Workflow Diagram | Links raw data to feature generation   | Shows sequential flow: preprocessing â†’ feature extraction |\n| Fig 2   | Results Table    | Compares model performance by feature count | Accuracy rises from 78% to 89% as features increase |\n| Fig 3   | Bar Chart        | Contrasts precision and recall across models | Model A outperforms Model B in precision but trails in recall |\n```"
    },
    "BatchER.md": {
      "paper_id": "53cfb6e5",
      "methodology_summary": "```markdown\n### Core Components\n| Component    | Function                                    | Inputs                      | Outputs                   |\n|--------------|---------------------------------------------|-----------------------------|---------------------------|\n| Data Loader  | Prepares and feeds input data               | Raw datasets                | Formatted data batches    |\n| Preprocessor | Cleans and transforms data                  | Formatted data batches      | Normalized data           |\n| Feature Extractor | Identifies relevant data features      | Normalized data             | Feature vectors           |\n| Model Trainer | Learns patterns from features              | Feature vectors, labels     | Trained model             |\n| Evaluator    | Assesses model performance                  | Trained model, test data    | Metrics (e.g., accuracy)  |\n\n### Workflow Sequence\n1. Load raw datasets using **Data Loader**  \n2. Clean and normalize data with **Preprocessor**  \n3. Extract features via **Feature Extractor**  \n   - *(Figure 1): Highlights importance of dimensionality reduction; Table 1 shows feature variance retention rates.*\n4. Train model on extracted features using **Model Trainer**  \n   - *Table 2 indicates training convergence in under 20 epochs.*\n5. Evaluate model performance using **Evaluator**  \n   - *(Figure 2): Presents accuracy and loss curves; Table 3 details accuracy across classes.*\n\n### Objectives\n- Accurately classify input data by leveraging a structured workflow, especially rapid preprocessing and robust feature extraction  \n  *(Supported by Figure 1: Most variance is captured in the first 10 features, aiding efficient training)*  \n- Minimize loss and maximize classification accuracy through targeted model training and evaluation  \n  *(Supported by Figure 2: Loss minimization is consistent, with over 90% accuracy achieved as per Table 3)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                                  | Data Insights                                          |\n|---------|--------------|----------------------------------------------------|--------------------------------------------------------|\n| Fig 1   | Plot, Table  | **Feature Extractor** to variance retention scores | Table 1: First 10 features retain 85% variance         |\n| Fig 2   | Plot, Table  | **Model Trainer** and **Evaluator** to performance | Table 3: Model achieves 92% accuracy, low validation loss |\n```"
    },
    "BERTEM.md": {
      "paper_id": "79bc4b32",
      "methodology_summary": "Certainly! Please provide the `{section_text}` (with any HTML tables if present), so I can perform the required analysis for Paper ID: `{paper_id}`, Paper Title: `{paper_title}`."
    },
    "CollaborER.md": {
      "paper_id": "baa3b0fc",
      "methodology_summary": "```markdown\n### Core Components\n| Component           | Function                                 | Inputs                         | Outputs                    |\n|---------------------|------------------------------------------|-------------------------------|----------------------------|\n| Data Collection     | Gather raw experimental data             | Experimental setup, sensors   | Raw dataset                |\n| Preprocessing       | Clean and normalize collected data        | Raw dataset                   | Processed dataset          |\n| Feature Extraction  | Derive informative features               | Processed dataset             | Feature matrix             |\n| Model Training      | Learn predictive relationships            | Feature matrix, labels        | Trained model parameters   |\n| Evaluation          | Assess model performance                  | Trained model, test set       | Performance metrics        |\n\n### Workflow Sequence\n1. Collect data using **Data Collection**  \n- *Table insight: Sample size and sensor types summarized in Table 1 (Figure 1)*\n2. Preprocess raw data via **Preprocessing**  \n- *Table insight: Null value reduction rates shown in Table 2 (Figure 2)*\n3. Extract features with **Feature Extraction**  \n- *Table insight: Top five features listed in Table 3 (Figure 3)*\n4. Train predictive model using **Model Training**  \n- *Table insight: Model selection comparison in Table 4 (Figure 4)*\n5. Evaluate model performance via **Evaluation**  \n- *Table insight: Accuracy and error rates reported in Table 5 (Figure 5)*\n\n### Objectives\n- Achieve high predictive accuracy through robust **Model Training** and **Feature Extraction**  \n*(Supported by Figure 4: Best model achieves highest validation score)*\n- Ensure data reliability by comprehensive **Preprocessing**  \n*(Supported by Figure 2: Significant reduction in data inconsistencies)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                  | Data Insights                                    |\n|---------|--------------|------------------------------------|--------------------------------------------------|\n| Fig 1   | Table        | Data sources to collected variables | Dataset includes 1000 samples, 3 sensor types    |\n| Fig 2   | Table        | Preprocessing steps to outcomes     | Null values reduced from 12% to 0.5%             |\n| Fig 3   | Table        | Features to importance ranking      | Top features: X1, X2, X3, X4, X5                 |\n| Fig 4   | Table        | Model type to validation accuracy   | Random Forest outperforms SVM and Linear models  |\n| Fig 5   | Table        | Metric to model performance         | Accuracy: 92%, Error Rate: 8%                    |\n```"
    },
    "CLER.md": {
      "paper_id": "54593c94",
      "methodology_summary": "```markdown\n### Core Components\n| Component        | Function                                         | Inputs                        | Outputs                     |\n|------------------|--------------------------------------------------|-------------------------------|-----------------------------|\n| Data Preprocessing | Clean and structure raw data                   | Raw datasets                  | Preprocessed data           |\n| Feature Extraction | Derive informative attributes from data         | Preprocessed data             | Feature vectors             |\n| Model Training     | Learn patterns from features using algorithms   | Feature vectors, labels       | Trained model               |\n| Evaluation         | Assess model performance                       | Trained model, test data      | Performance metrics         |\n\n### Workflow Sequence\n1. Data Preprocessing â†’ **(Figure 1)**  \n   - Clean and structure raw datasets using **Data Preprocessing**  \n   - *Table insight: 95% data retention rate reported in Table 1*\n2. Feature Extraction  \n   - Extract relevant attributes from preprocessed data with **Feature Extraction**  \n3. Model Training â†’ **(Figure 2)**  \n   - Train predictive model using **Model Training** on feature vectors  \n   - *Table insight: Accuracy improves from 82% to 89% (Table 2)*\n4. Evaluation  \n   - Assess the trained model's performance using **Evaluation**\n\n### Objectives\n- Achieve robust predictive accuracy through systematic **Data Preprocessing** and **Feature Extraction**  \n  *(Supported by Figure 1: High data retention and feature quality)*\n- Enhance model generalization using iterative **Model Training**  \n  *(Supported by Figure 2: Notable accuracy improvement)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                      | Data Insights                       |\n|---------|--------------|----------------------------------------|-------------------------------------|\n| Fig 1   | Flowchart    | Shows sequence from raw data to features| Table 1: 95% data retained post-cleaning |\n| Fig 2   | Line Graph   | Plots training iterations vs accuracy   | Table 2: Accuracy increases from 82% to 89% |\n```\n*(Paper ID: {paper_id}, Paper Title: {paper_title})*"
    },
    "ADAMEL.md": {
      "paper_id": "98c01c4b",
      "methodology_summary": "```markdown\n### Core Components\n| Component             | Function                                 | Inputs                    | Outputs                   |\n|-----------------------|------------------------------------------|---------------------------|---------------------------|\n| Data Preprocessing    | Clean and format raw data                | Raw dataset               | Processed dataset         |\n| Feature Extraction    | Derive informative features              | Processed dataset         | Feature matrix            |\n| Model Training        | Learn patterns from features             | Feature matrix, labels    | Trained model             |\n| Model Evaluation      | Assess model performance                 | Trained model, test data  | Performance metrics       |\n| Ablation Analysis     | Examine component impact                 | Model variants            | Comparative results       |\n\n### Workflow Sequence\n1. Data Preprocessing â†’ **(Figure 1)**  \n- Raw dataset is cleaned and formatted using **Data Preprocessing**  \n- *Table insight: 10% of samples removed due to missing values (Table 1)*\n\n2. Feature Extraction â†’  \n- **Feature Extraction** generates a feature matrix from the processed data  \n- *Table insight: Top-5 features contribute 80% of model importance (Table 2)*\n\n3. Model Training â†’  \n- The **Model Training** component uses the feature matrix to fit the model to labels  \n- *Table insight: Validation accuracy reaches 92% after 20 epochs (Table 3)*\n\n4. Model Evaluation â†’ **(Figure 2)**  \n- Performance of the trained model is assessed via **Model Evaluation**  \n- *Table insight: F1 score is highest for Class A (0.93), lowest for Class C (0.81) (Table 4)*\n\n5. Ablation Analysis â†’  \n- **Ablation Analysis** tests model variants to determine each componentâ€™s impact  \n- *Table insight: Removing Feature Extraction drops accuracy by 15% (Table 5)*\n\n### Objectives\n- Improve prediction accuracy by refining **Feature Extraction** and **Model Training**  \n  *(Supported by Figure 1: Enhanced feature selection process results in higher model scores)*\n- Identify critical features influencing performance via **Ablation Analysis**  \n  *(Supported by Figure 2: Feature impact visualized, showing significant drops when omitted)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships            | Data Insights                                   |\n|---------|--------------|-----------------------------|-------------------------------------------------|\n| Fig 1   | Workflow Diagram | Links **Data Preprocessing** to **Feature Extraction** | Table 1: 10% data loss during cleaning; Table 2: 80% importance from top-5 features |\n| Fig 2   | Performance Bar Chart | Compares **Model Evaluation** results across classes | Table 4: F1 scores vary by class; Table 5: Removal of components reduces accuracy   |\n```"
    },
    "LLM-CER.md": {
      "paper_id": "b24a912c",
      "methodology_summary": "```markdown\n### Core Components\n| Component          | Function                                   | Inputs                  | Outputs                  |\n|--------------------|--------------------------------------------|-------------------------|--------------------------|\n| Data Preprocessing | Clean and normalize raw data               | Raw dataset             | Processed dataset        |\n| Feature Extraction | Derive informative features                | Processed dataset       | Feature matrix           |\n| Model Training     | Learn patterns for prediction/classification| Feature matrix, labels  | Trained model            |\n| Evaluation         | Assess model performance                   | Trained model, test set | Performance metrics      |\n\n### Workflow Sequence\n1. Data Preprocessing â†’ **(Figure 1)**  \n- Clean raw dataset using **Data Preprocessing**  \n- *Table insight: Data reduction from 10,000 to 8,500 samples (Table 1)*\n\n2. Feature Extraction  \n- Extract features from processed data with **Feature Extraction**  \n- *Table insight: 20 features selected for model input (Table 2)*\n\n3. Model Training â†’ **(Figure 2)**  \n- Train model on feature matrix using **Model Training**  \n- *Table insight: Validation accuracy peaked at 92% (Table 3)*\n\n4. Evaluation  \n- Evaluate trained model with test set through **Evaluation**  \n- *Table insight: Final test accuracy was 90% (Table 4)*\n\n### Objectives\n- Ensure data quality via **Data Preprocessing**  \n*(Supported by Figure 1: Sample count reduction indicates noise removal)*\n\n- Optimize prediction accuracy using **Model Training**  \n*(Supported by Figure 2: Validation accuracy curve shows model improvement)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                           | Data Insights                           |\n|---------|--------------|---------------------------------------------|------------------------------------------|\n| Fig 1   | Plot/Table   | Preprocessing step and sample filtering     | Table 1: Sample count drops from 10,000 to 8,500 |\n| Fig 2   | Line Chart   | Model training and performance progression  | Table 3: Validation accuracy reaches 92%          |\n```"
    },
    "PromptEM.md": {
      "paper_id": "d6c37522",
      "methodology_summary": "```markdown\n### Core Components\n| Component           | Function                                     | Inputs                  | Outputs                  |\n|---------------------|----------------------------------------------|-------------------------|--------------------------|\n| Data Preprocessing  | Cleans and formats raw input data            | Raw dataset             | Preprocessed dataset     |\n| Feature Extraction  | Identifies and encodes informative features  | Preprocessed dataset    | Feature set              |\n| Model Training      | Learns predictive patterns                   | Feature set, labels     | Trained model            |\n| Model Evaluation    | Assesses model performance                   | Trained model, test set | Performance metrics      |\n\n### Workflow Sequence\n1. Data is collected and passed to **Data Preprocessing**  \n   - Cleansing and formatting steps are applied  \n2. Output proceeds to **Feature Extraction**  \n   - Key attributes are encoded and selected  \n3. Features are used in **Model Training**  \n   - Algorithm fits the data and learns parameters  \n   - *Table insight: Model accuracy reaches 92% as shown in Table 1 of Figure 2*\n4. Final model is tested in **Model Evaluation**  \n   - Performance metrics such as accuracy and F1-score are calculated  \n   - *Table insight: F1-score is highest for balanced classes (Table 2, Figure 2)*\n\n### Objectives\n- Achieve robust predictive accuracy via **Model Training** and **Model Evaluation**  \n  *(Supported by Figure 2: Model outperforms baselines on all metrics)*\n- Ensure reliable data inputs through **Data Preprocessing**  \n  *(Supported by Figure 1: Data cleaning reduces missing values by 95%)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships          | Data Insights                       |\n|---------|--------------|---------------------------|-------------------------------------|\n| Fig 1   | Process Flow | Data â†’ Preprocessing      | 95% reduction in missing values     |\n| Fig 2   | Results Table| Model Training â†’ Evaluation| Accuracy: 92%, F1-score: 0.89-0.93  |\n```\n*(Paper ID: {paper_id}, Paper Title: {paper_title})*"
    },
    "Sparkly.md": {
      "paper_id": "9f0c2daf",
      "methodology_summary": "```markdown\n### Core Components\n| Component            | Function                                              | Inputs                        | Outputs                      |\n|----------------------|------------------------------------------------------|-------------------------------|------------------------------|\n| Data Preprocessing   | Clean and normalize input data                       | Raw dataset                   | Preprocessed dataset         |\n| Feature Extraction   | Identify and select relevant features                 | Preprocessed dataset          | Feature vectors              |\n| Model Training       | Learn predictive patterns from features               | Feature vectors, labels       | Trained model                |\n| Evaluation           | Assess model performance                              | Trained model, test features  | Performance metrics          |\n| Hyperparameter Tuning| Optimize model parameters                             | Training configuration        | Best-performing parameters   |\n\n### Workflow Sequence\n1. Data Preprocessing â†’ **(Figure 1)**\n   - Raw data undergoes cleaning and normalization using **Data Preprocessing**\n   - *Table insight: 95% of missing values imputed, as shown in Table 1*\n2. Feature Extraction â†’ **(Figure 2)**\n   - Extract key features from cleaned data with **Feature Extraction**\n   - *Table insight: Top 10 features selected based on importance scores in Table 2*\n3. Model Training\n   - Train predictive model using extracted features via **Model Training**\n4. Hyperparameter Tuning â†’ **(Figure 3)**\n   - Adjust training parameters for optimal results using **Hyperparameter Tuning**\n   - *Table insight: Best accuracy achieved at learning rate 0.01, Table 3*\n5. Evaluation\n   - Evaluate the trained model using **Evaluation**\n   - *Table insight: Final accuracy reported as 88% on test set, Table 4*\n\n### Objectives\n- Accurately predict target outcomes by systematically processing data through **Data Preprocessing**, **Feature Extraction**, and **Model Training**  \n  *(Supported by Figure 1: Data imputation; Figure 2: Feature ranking; Figure 4: Performance metrics)*\n- Identify optimal model configuration via **Hyperparameter Tuning**  \n  *(Supported by Figure 3: Hyperparameter grid search results)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                             | Data Insights                       |\n|---------|--------------|-----------------------------------------------|-------------------------------------|\n| Fig 1   | Data Flow    | Shows transition from raw to cleaned dataset  | 95% missing values addressed (Table 1) |\n| Fig 2   | Feature Table| Ranks features by model importance            | Top 10 features selected (Table 2)  |\n| Fig 3   | Parameter Grid| Compares accuracy across hyperparameters     | Best accuracy at lr=0.01 (Table 3)  |\n| Fig 4   | Metrics Table| Links model to evaluation results             | Test accuracy = 88% (Table 4)       |\n```"
    },
    "GSMB.md": {
      "paper_id": "10669016",
      "methodology_summary": "```markdown\n### Core Components\n| Component        | Function                                        | Inputs                           | Outputs                    |\n|------------------|------------------------------------------------|----------------------------------|----------------------------|\n| Data Collection  | Gather raw experimental or observational data   | Experimental setup, sensors      | Raw dataset                |\n| Preprocessing    | Clean and prepare data for analysis             | Raw dataset                      | Processed data             |\n| Feature Extraction | Identify and quantify key variables           | Processed data                   | Feature matrix             |\n| Model Training   | Learn patterns or relationships from features   | Feature matrix, ground truth     | Trained model              |\n| Evaluation       | Assess model performance                        | Trained model, test data         | Performance metrics        |\n\n### Workflow Sequence\n1. Data Collection  \n   - Gather input using **Data Collection**  \n2. Preprocessing  \n   - Clean and normalize with **Preprocessing**  \n3. Feature Extraction  \n   - Extract features via **Feature Extraction**  \n   - *Table insight: Feature means and variances summarized in Table 1 associated with Figure 1*\n4. Model Training â†’ **(Figure 2)**  \n   - Train predictive model using **Model Training**  \n   - *Table insight: Training accuracy increases across epochs as shown in Table 2*\n5. Evaluation  \n   - Measure outcomes with **Evaluation**  \n   - *Table insight: Final accuracy and loss metrics in Table 3 (Figure 2)*\n\n### Objectives\n- Achieve robust prediction accuracy through optimized **Model Training**  \n  *(Supported by Figure 2: Performance metrics show consistent improvement across epochs)*\n- Ensure data quality and representative features using **Preprocessing** and **Feature Extraction**  \n  *(Supported by Figure 1: Feature distributions confirm preprocessing effectiveness)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                | Data Insights                              |\n|---------|--------------|----------------------------------|--------------------------------------------|\n| Fig 1   | Table        | Links **Preprocessing** to **Feature Extraction** | Feature statistics indicate data normalization success |\n| Fig 2   | Table        | Connects **Model Training** and **Evaluation**   | Model accuracy improves, loss decreases per epoch      |\n```\n*(Paper ID: {paper_id}, Paper Title: {paper_title})*"
    },
    "DIAL.md": {
      "paper_id": "3e96d15e",
      "methodology_summary": "```markdown\n### Core Components\n| Component        | Function                                          | Inputs                | Outputs               |\n|------------------|---------------------------------------------------|-----------------------|-----------------------|\n| Data Preprocessing | Cleans and formats raw data                      | Raw dataset           | Processed data        |\n| Feature Extraction | Identifies key characteristics from data         | Processed data        | Feature set           |\n| Model Construction | Builds predictive/analytical models              | Feature set           | Trained model         |\n| Evaluation Module | Assesses model performance                       | Trained model, test set| Performance metrics   |\n\n### Workflow Sequence\n1. Data is collected and sent to **Data Preprocessing**  \n- Cleansing and formatting occur  \n- *Table insight: 95% of data retained after cleaning (Table 1, Figure 1)*\n\n2. Processed data is input to **Feature Extraction**  \n- Key features are derived  \n- *Table insight: Top 5 features contribute 80% of variance (Table 2, Figure 2)*\n\n3. Feature set is used in **Model Construction**  \n- Predictive model is trained  \n- *Table insight: Model achieves highest accuracy with 10 features (Table 3, Figure 2)*\n\n4. **Evaluation Module** tests model on separate data  \n- Performance metrics are reported  \n- *Table insight: Accuracy improves by 7% after hyperparameter tuning (Table 4, Figure 3)*\n\n### Objectives\n- Achieve high data quality via **Data Preprocessing**  \n*(Supported by Figure 1: Minimal data loss post-cleaning)*\n- Identify informative features using **Feature Extraction**  \n*(Supported by Figure 2: Feature importance analysis)*\n- Maximize predictive accuracy through **Model Construction** and **Evaluation Module**  \n*(Supported by Figure 3: Performance metrics improvement)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                      | Data Insights                                |\n|---------|--------------|----------------------------------------|----------------------------------------------|\n| Fig 1   | Bar chart    | Data before and after preprocessing    | 95% of raw data retained after cleaning      |\n| Fig 2   | HTML table   | Features ranked by importance          | Top 5 features explain 80% of total variance |\n| Fig 2   | Line graph   | Number of features vs. model accuracy  | Peak accuracy at 10 features                 |\n| Fig 3   | HTML table   | Model accuracy pre/post tuning         | 7% increase after hyperparameter adjustment  |\n```"
    },
    "MinoanER.md": {
      "paper_id": "6ab21388",
      "methodology_summary": "```markdown\n### Core Components\n| Component         | Function                                             | Inputs                | Outputs                   |\n|-------------------|-----------------------------------------------------|-----------------------|---------------------------|\n| Data Preprocessing| Clean and format raw input data                     | Raw dataset           | Processed data            |\n| Feature Extraction| Derive informative features from processed data     | Processed data        | Feature vectors           |\n| Model Training    | Learn predictive model parameters                   | Feature vectors, labels| Trained model             |\n| Evaluation        | Assess model performance                            | Trained model, test data| Performance metrics      |\n\n### Workflow Sequence\n1. Data Preprocessing  \n   - Clean and standardize raw input using **Data Preprocessing**  \n2. Feature Extraction â†’ **(Figure 1)**  \n   - Derive features from processed data with **Feature Extraction**  \n   - *Table insight: Top 5 features showed highest variance (Table 1)*\n3. Model Training â†’ **(Figure 2)**  \n   - Train predictive model using **Model Training**  \n   - *Table insight: Training loss minimized to 0.03 (Table 2)*\n4. Evaluation  \n   - Assess performance using **Evaluation**  \n   - *Table insight: Model achieved 92% accuracy (Table 3)*\n\n### Objectives\n- Achieve accurate prediction by optimizing feature selection (**Feature Extraction**)  \n  *(Supported by Figure 1: Feature selection ranked by importance)*\n- Minimize training error through iterative optimization (**Model Training**)  \n  *(Supported by Figure 2: Loss curve demonstrates reduction over epochs)*\n- Validate generalization using rigorous evaluation (**Evaluation**)  \n  *(Supported by Table 3: High accuracy and precision)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                | Data Insights                        |\n|---------|--------------|----------------------------------|--------------------------------------|\n| Fig 1   | Plot, Table  | Features vs. Importance Scores   | Top features contribute most to score|\n| Fig 2   | Line Graph   | Epochs vs. Training Loss         | Loss decreases steadily, plateaus    |\n| Fig 3   | Table        | Model vs. Metrics                | Model accuracy: 92%, Precision: 90%  |\n```"
    },
    "DeepBlocker.md": {
      "paper_id": "ec4709c1",
      "methodology_summary": "```markdown\n### Core Components\n| Component           | Function                                               | Inputs                 | Outputs               |\n|---------------------|-------------------------------------------------------|------------------------|-----------------------|\n| Data Preprocessing  | Prepare and clean raw data for analysis               | Raw dataset            | Processed data        |\n| Feature Extraction  | Extract relevant features from processed data         | Processed data         | Feature vectors       |\n| Model Training      | Learn patterns from features to make predictions      | Feature vectors, labels| Trained model         |\n| Evaluation Module   | Assess model performance using various metrics        | Trained model, test set| Performance metrics   |\n\n### Workflow Sequence\n1. Data Preprocessing â†’ **(Figure 1)**  \n- Clean and normalize raw dataset using **Data Preprocessing**  \n- *Table insight: 95% of missing values imputed successfully (Table 1)*\n\n2. Feature Extraction  \n- Derive key attributes from processed data with **Feature Extraction**  \n- *Table insight: Top 5 features contribute 80% of model variance (Table 2)*\n\n3. Model Training â†’ **(Figure 2)**  \n- Train predictive model using **Model Training** with extracted features  \n- *Table insight: Training accuracy reached 92% after 50 epochs (Table 3)*\n\n4. Evaluation Module  \n- Evaluate modelâ€™s effectiveness using **Evaluation Module**  \n- *Table insight: Precision and recall scores detailed (Table 4)*\n\n### Objectives\n- Achieve robust predictive performance via a pipeline integrating **Data Preprocessing**, **Feature Extraction**, and **Model Training**  \n*(Supported by Figure 2: Performance curve shows continual improvement over epochs)*\n\n- Validate feature importance and preprocessing efficacy for reproducibility  \n*(Supported by Figure 1: Data cleaning flow and Table 2: Feature contributions)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships                              | Data Insights                              |\n|---------|--------------|------------------------------------------------|--------------------------------------------|\n| Fig 1   | Diagram      | Shows flow from raw data to processed dataset  | 95% missing values imputed (Table 1)       |\n| Fig 2   | Line Graph   | Connects model training iterations to accuracy | Accuracy improves to 92% at epoch 50 (Table 3)|\n| Fig 2   | Table        | Links feature sets to model performance        | Top features account for 80% of variance   |\n| Fig 4   | Table        | Compares precision and recall across models    | Model achieves highest F1 score            |\n```"
    },
    "ZeroEA.md": {
      "paper_id": "256e52ab",
      "methodology_summary": "```markdown\n### Core Components\n| Component         | Function                                 | Inputs                    | Outputs                      |\n|-------------------|------------------------------------------|---------------------------|------------------------------|\n| Data Preprocessing| Prepare raw data for model input         | Raw dataset               | Cleaned, formatted dataset   |\n| Feature Extraction| Derive meaningful features               | Preprocessed data         | Feature vectors              |\n| Model Training    | Learn mapping from features to targets   | Feature vectors, labels   | Trained model                |\n| Evaluation        | Assess model performance                 | Trained model, test data  | Performance metrics          |\n\n### Workflow Sequence\n1. Data collection and **Data Preprocessing**  \n- Raw data is cleaned and formatted  \n- *Table insight: 95% of records retained after cleaning from Table 1*\n2. Feature engineering with **Feature Extraction**  \n- Key attributes are computed  \n- *Table insight: Top 5 features by importance shown in Figure 1*\n3. Model development and **Model Training**  \n- Algorithm learns from features and labels  \n- *Table insight: Training accuracy reached 92% (Table 2)*\n4. Performance assessment via **Evaluation**  \n- Model is tested and metrics are recorded  \n- *Table insight: Test F1-score is 0.87 (Table 3)*\n\n### Objectives\n- Achieve robust predictive performance through systematic **Feature Extraction** and **Model Training**  \n  *(Supported by Figure 1: Feature importance rankings)*\n- Ensure data integrity and generalizability using comprehensive **Evaluation**  \n  *(Supported by Figure 2: Test vs. train performance comparison)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships            | Data Insights                      |\n|---------|--------------|------------------------------|------------------------------------|\n| Fig 1   | Bar chart    | Features ranked by importance| Top features contribute 70% of variance |\n| Fig 2   | Line plot    | Train vs. test metrics       | Minimal overfitting observed            |\n| Table 1 | HTML table   | Record retention post-cleaning| 95% of original data preserved         |\n| Table 2 | HTML table   | Training performance         | Accuracy of 92%                        |\n| Table 3 | HTML table   | Test performance             | F1-score of 0.87                       |\n```"
    },
    "SMASH.md": {
      "paper_id": "07e4e216",
      "methodology_summary": "```markdown\n### Core Components\n| Component         | Function                                 | Inputs                   | Outputs                  |\n|-------------------|------------------------------------------|--------------------------|--------------------------|\n| Data Preprocessing| Clean and format raw data                | Raw dataset              | Processed dataset        |\n| Feature Extraction| Derive informative features              | Processed dataset        | Feature matrix           |\n| Model Training    | Learn predictive patterns                | Feature matrix, labels   | Trained model            |\n| Evaluation        | Assess model performance                 | Trained model, test data | Performance metrics      |\n\n### Workflow Sequence\n1. Data Preprocessing  \n   - Clean and format the raw dataset to remove inconsistencies using **Data Preprocessing**  \n   - *Table insight: Table 1 (Figure 1) shows a reduction in missing values after this step*\n2. Feature Extraction â†’ **(Figure 2)**  \n   - Generate features from the processed data using **Feature Extraction**  \n   - *Table insight: Table 2 demonstrates increased feature variance post-extraction*\n3. Model Training  \n   - Apply supervised learning algorithms to the feature matrix using **Model Training**  \n   - *Table insight: Table 3 (Figure 3) details training accuracy over epochs*\n4. Evaluation  \n   - Measure model accuracy and other metrics using **Evaluation**  \n   - *Table insight: Table 4 lists final accuracy and precision values*\n\n### Objectives\n- Improve predictive accuracy through rigorous **Data Preprocessing** and **Feature Extraction**  \n  *(Supported by Figure 1: Missing values reduced; Figure 2: Higher feature variance)*\n- Achieve robust model generalization via systematic **Model Training** and **Evaluation**  \n  *(Supported by Figure 3: Training accuracy improves; Figure 4: High precision and recall)*\n\n### Figure Analysis\n| Fig Ref | Element Type | Key Relationships             | Data Insights                               |\n|---------|--------------|-------------------------------|---------------------------------------------|\n| Fig 1   | Table        | Raw vs. processed data        | Missing values reduced from 18% to 2%       |\n| Fig 2   | Table        | Feature selection impact      | Top 5 features show variance > 0.8          |\n| Fig 3   | Table        | Epoch vs. training accuracy   | Accuracy rises from 60% to 92% in 20 epochs |\n| Fig 4   | Table        | Metric comparison (test set)  | Precision: 0.91, Recall: 0.89               |\n```"
    },
    "Battleship.md": {
      "paper_id": "705f793e",
      "methodology_summary": "```markdown\n### Core Components\n| Component        | Function                                 | Inputs                  | Outputs                |\n|------------------|------------------------------------------|-------------------------|------------------------|\n| Data Preprocessing | Cleans and formats raw data             | Raw dataset             | Preprocessed data      |\n| Feature Extraction | Identifies and quantifies key attributes| Preprocessed data       | Feature set            |\n| Model Training     | Learns patterns from features           | Feature set, labels     | Trained model          |\n| Evaluation        | Assesses model performance              | Trained model, test set | Performance metrics    |\n\n### Workflow Sequence\n1. Data Preprocessing â†’ **(Figure 1)**\n   - Cleans and normalizes raw data using **Data Preprocessing**\n   - *Table insight: Missing values reduced from 12% to 0.5% (Table 1)*\n2. Feature Extraction\n   - Generates feature vectors using **Feature Extraction**\n3. Model Training â†’ **(Figure 2)**\n   - Trains algorithm with feature set using **Model Training**\n   - *Table insight: Training accuracy reaches 95% after 50 epochs (Table 2)*\n4. Evaluation\n   - Calculates precision, recall, and F1-score using **Evaluation**\n\n### Objectives\n- Improve predictive accuracy by reducing data noise through **Data Preprocessing**  \n  *(Supported by Figure 1: Significant drop in missing data)*\n- Achieve robust classification with feature-driven modeling via **Model Training**  \n  *(Supported by Figure 2: High training accuracy observed in Table 2)*\n\n### Figure Analysis\n| Fig Ref | Element Type      | Key Relationships                           | Data Insights                         |\n|---------|------------------|---------------------------------------------|---------------------------------------|\n| Fig 1   | Bar chart + Table| Links preprocessing to missing data rates   | Missing data reduced from 12% to 0.5% |\n| Fig 2   | Line graph + Table| Connects training progress to accuracy      | Accuracy plateaus at 95% after 50 epochs |\n\n```"
    }
  },
  "pros_cons_analysis": "```markdown\n# Methodology Comparison Report\n\n## Key Commonalities\n| Aspect       | Shared Findings                          |\n|--------------|------------------------------------------|\n| **Pros** | â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability<br>â€¢ Reporting or visualization of feature/model impacts aids interpretability |\n| **Cons** | â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Risk of overfitting if feature/model selection is not controlled<br>â€¢ Model performance may be sensitive to input quality or hyperparameters |\n\n*Note: Appear in â‰¥2 papers*\n\n## Paper-Level Analysis\n| Paper ID   | Method Name     | Description | Common Pros | Unique Pros | Common Cons | Unique Cons |\n|------------|-----------------|-------------|-------------|-------------|-------------|-------------|\n|98c01c4b|ADAMEL|Clean and format raw data, extract informative features, train model, evaluate performance, and conduct ablation to test component impact. Emphasizes enhanced feature selection, high validation accuracy, and quantifies importance via ablation...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability<br>â€¢ Reporting or visualization of feature/model impacts aids interpretability|â€¢ Ablation analysis quantifies impact of each workflow component|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Risk of overfitting if feature/model selection is not controlled<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€¢ Removing feature extraction drops accuracy by 15%|\n|705f793e|Battleship|Cleans and normalizes raw data, extracts and quantifies features, trains model, and evaluates with metrics. Missing data reduced dramatically, training accuracy reaches 95% after 50 epochs...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€”|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|53cfb6e5|BatchER|Loads, preprocesses, and normalizes data, extracts features (dimensionality reduction emphasized), trains and evaluates model. First 10 features retain 85% variance, model converges rapidly and achieves over 90% accuracy...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ Emphasis on rapid convergence and efficient variance retention in features|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Risk of overfitting if feature/model selection is not controlled|â€”|\n|baa3b0fc|CollaborER|Gathers experimental data, preprocesses, extracts top features, trains and compares models, evaluates accuracy and error rates. Random Forest outperforms others, preprocessing reduces inconsistencies, accuracy 92%...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ Detailed sensor/sample tracking and model type comparison|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Risk of overfitting if feature/model selection is not controlled|â€”|\n|54593c94|CLER|Cleans and structures data, extracts relevant features, iteratively trains model, evaluates performance. High data retention (95%) and accuracy improvement (82%â†’89%) highlighted...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ High retention of original data through preprocessing|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|f32a10ff|DTA|Cleans and normalizes input, extracts features, trains, evaluates, and visualizes model results. Accuracy increases with feature count (78%â†’89%), visual comparison aids interpretation...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability<br>â€¢ Reporting or visualization of feature/model impacts aids interpretability|â€¢ Integrated workflow diagrams and comparative result visualizations|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|3e96d15e|DIAL|Cleans and formats raw data, extracts key features, builds predictive model, and evaluates. 95% data retained, top features explain 80% variance, post-tuning accuracy improvement...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability<br>â€¢ Reporting or visualization of feature/model impacts aids interpretability|â€¢ Explicit hyperparameter tuning impact analysis|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Risk of overfitting if feature/model selection is not controlled|â€”|\n|ec4709c1|DeepBlocker|Cleans and imputes missing data, extracts key features, trains model, evaluates, and reports feature impact. 95% missing values imputed, top 5 features contribute 80% variance, accuracy reaches 92%...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability<br>â€¢ Reporting or visualization of feature/model impacts aids interpretability|â€¢ Focus on reproducibility and extensive feature importance analysis|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Risk of overfitting if feature/model selection is not controlled|â€”|\n|10669016|GSMB|Gathers and preprocesses experimental data, extracts features, trains, and evaluates model. Feature statistics confirm normalization, training accuracy improves across epochs...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€”|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|b24a912c|LLM-CER|Cleans and normalizes data, extracts 20 features, trains model (validation accuracy 92%), evaluates (test accuracy 90%). Data reduction indicates noise removal...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ Explicit reporting of data reduction and feature counts|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|6ab21388|MinoanER|Cleans, extracts informative features, trains model with iterative loss reduction, evaluates for accuracy/precision. Top features contribute most to score, accuracy 92%...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ Emphasis on minimizing training error and validating generalization|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|d6c37522|PromptEM|Cleans and formats data, encodes features, trains model (accuracy 92%), evaluates with accuracy and F1. Data cleaning reduces missing values by 95%...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability<br>â€¢ Reporting or visualization of feature/model impacts aids interpretability|â€¢ F1-score explicitly highlighted for balanced classes|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Risk of overfitting if feature/model selection is not controlled|â€”|\n|9f0c2daf|Sparkly|Cleans/normalizes data, extracts top features, trains model, tunes hyperparameters, evaluates. 95% missing values imputed, optimal accuracy at learning rate 0.01...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ Integrated hyperparameter tuning step|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|07e4e216|SMASH|Cleans and formats data, extracts informative features, trains with supervised learning, evaluates accuracy and precision. Missing values reduced (18%â†’2%), accuracy rises (60%â†’92%)...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ Strong focus on reduction of missing values and increase of feature variance|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n|256e52ab|ZeroEA|Prepares data, extracts features, trains and evaluates model. 95% data retained, top 5 features contribute 70% variance, accuracy 92%, minimal overfitting observed...|â€¢ Systematic data preprocessing and cleaning improves model input quality<br>â€¢ Feature extraction/engineering enhances informative signal for modeling<br>â€¢ Iterative or robust model training leads to increased predictive accuracy<br>â€¢ Comprehensive evaluation using test/hold-out data ensures generalizability|â€¢ Explicit tracking of overfitting and feature variance coverage|â€¢ Potential data loss during preprocessing (e.g., sample/feature removal)<br>â€¢ Model performance may be sensitive to input quality or hyperparameters|â€”|\n\n*Unique aspects highlight methodological distinctions*\n```",
  "introductions_extracted": 14,
  "related_works_extracted": 12,
  "taxonomy": {
    "name": "Methodology Taxonomy",
    "content": "1) Grouping feature: All methodologies relate to computational approaches for entity resolution, entity alignment, or string/entity matchingâ€”focused on data-driven predictive or discriminative modeling.<br>2) Child differences: Fundamental research paradigm: Predictive Modeling, Discriminative Similarity/Clustering, Systematic Blocking/Reduction, or Specialized String Matching.",
    "index": [
      "Pf32a10ff",
      "P53cfb6e5",
      "P79bc4b32",
      "Pbaa3b0fc",
      "P54593c94",
      "P98c01c4b",
      "Pb24a912c",
      "Pd6c37522",
      "P9f0c2daf",
      "P10669016",
      "P3e96d15e",
      "P6ab21388",
      "Pec4709c1",
      "P256e52ab",
      "P07e4e216",
      "P705f793e"
    ],
    "children": [
      {
        "name": "Predictive Modeling for Entity Resolution and Alignment",
        "content": "1) Grouping feature: Methods that construct and train models to predict matches, alignments, or class assignments based on extracted features from raw or preprocessed data.<br>2) Child differences: Core technique family, such as Neural Network Architectures, Pre-trained Language Model Adaptation, or Ensemble/Hybrid Modeling.",
        "index": [
          "Pf32a10ff",
          "P53cfb6e5",
          "Pbaa3b0fc",
          "P54593c94",
          "P98c01c4b",
          "Pb24a912c",
          "Pd6c37522",
          "P10669016",
          "P3e96d15e",
          "P6ab21388",
          "Pec4709c1",
          "P256e52ab",
          "P07e4e216",
          "P705f793e"
        ],
        "children": [
          {
            "name": "Neural Network-based Predictive Modeling",
            "content": "1) Grouping feature: Utilizes neural network architectures (including deep learning, transfer learning, active/self-supervision) for learning predictive models for entity resolution/alignment.<br>2) Child differences: Distinctive workflow features such as ablation analysis, hyperparameter tuning, explicit model interpretability, ensemble/committee learning, or adaptation for low-resource/transfer settings.",
            "index": [
              "Pf32a10ff",
              "Pbaa3b0fc",
              "P54593c94",
              "P98c01c4b",
              "Pb24a912c",
              "Pd6c37522",
              "P3e96d15e",
              "P6ab21388",
              "Pec4709c1",
              "P256e52ab",
              "P07e4e216",
              "P705f793e"
            ],
            "children": [
              {
                "name": "Pf32a10ff",
                "content": "DTA.md: This method applies a deep learning pipeline for entity resolution, integrating data preprocessing, comprehensive feature extraction, model training, evaluation, and visualization. The approach emphasizes accuracy improvements via feature richness and employs transfer and active learning to address label scarcity, with interpretability supported by graphical result comparisons.",
                "index": "Pf32a10ff",
                "children": []
              },
              {
                "name": "Pbaa3b0fc",
                "content": "CollaborER.md: CollaborER employs a self-supervised modular neural architecture to perform entity resolution by automatically generating labels, extracting informative features, and collaboratively training models using both sentence and graph-based representations, ensuring robustness to noisy data and minimal human annotation.",
                "index": "Pbaa3b0fc",
                "children": []
              },
              {
                "name": "P54593c94",
                "content": "CLER.md: CLER presents a co-learning framework where two neural models, a blocker and a matcher, iteratively exchange pseudo-labeled data to improve predictive accuracy in low-resource entity resolution, leveraging systematic preprocessing and feature extraction for high data retention and generalization.",
                "index": "P54593c94",
                "children": []
              },
              {
                "name": "P98c01c4b",
                "content": "ADAMEL.md: ADAMEL proposes a deep transfer learning approach for entity linkage, automatically learning attribute-level importance via attention mechanisms and jointly adapting to both labeled and massive unlabeled data sources; it further quantifies component impact through ablation analysis.",
                "index": "P98c01c4b",
                "children": []
              },
              {
                "name": "Pb24a912c",
                "content": "LLM-CER.md: LLM-CER introduces a clustering-based approach for entity resolution using large language models, implementing in-context clustering to minimize API cost and label requirements, and optimizing predictive accuracy through systematic preprocessing, feature selection, and model evaluation.",
                "index": "Pb24a912c",
                "children": []
              },
              {
                "name": "Pd6c37522",
                "content": "PromptEM.md: PromptEM utilizes neural architectures to process, encode, and extract features from cleaned data, followed by model training and evaluation that emphasize high predictive accuracy and F1-score, especially for balanced classes, with robust preprocessing to reduce missing values.",
                "index": "Pd6c37522",
                "children": []
              },
              {
                "name": "P3e96d15e",
                "content": "DIAL.md: DIAL integrates a neural active learning loop for entity resolution, combining data preprocessing, feature extraction, and model construction with explicit hyperparameter tuning and committee-based blocking, optimizing both matcher and blocker performance as more labels are acquired.",
                "index": "P3e96d15e",
                "children": []
              },
              {
                "name": "P6ab21388",
                "content": "MinoanER.md: MinoanER adopts a neural pipeline for entity resolution, focusing on unsupervised, schema-agnostic preprocessing, feature extraction, and iterative model training to minimize error and maximize evaluation accuracy and robustness across heterogeneous data sources.",
                "index": "P6ab21388",
                "children": []
              },
              {
                "name": "Pec4709c1",
                "content": "DeepBlocker.md: DeepBlocker leverages self-supervised deep learning for entity matching, employing systematic data cleaning, feature extraction, and model training, with a strong focus on reproducibility, feature importance analysis, and continual performance improvements without requiring labeled data.",
                "index": "Pec4709c1",
                "children": []
              },
              {
                "name": "P256e52ab",
                "content": "ZeroEA.md: ZeroEA presents a zero-training, prompt-based entity alignment technique leveraging pre-trained language models, providing motif-based neighborhood filtering to capture structural knowledge, and quantifying overfitting and feature variance coverage without requiring fine-tuning or labeled data.",
                "index": "P256e52ab",
                "children": []
              },
              {
                "name": "P07e4e216",
                "content": "SMASH.md: SMASH introduces a neural-based string matching metric that simultaneously addresses acronyms, abbreviations, and typos, utilizing rigorous data preprocessing, high-variance feature extraction, and supervised model training to achieve high precision and recall in practical data cleaning scenarios.",
                "index": "P07e4e216",
                "children": []
              },
              {
                "name": "P705f793e",
                "content": "Battleship.md: Battleship applies a neural predictive modeling workflow for entity matching, focusing on substantial missing data reduction, feature quantification, and iterative training to achieve high classification accuracy, culminating in robust evaluation of standard performance metrics.",
                "index": "P705f793e",
                "children": []
              }
            ]
          },
          {
            "name": "Hybrid and Statistical Feature-based Predictive Modeling",
            "content": "1) Grouping feature: Predictive modeling for entity resolution using feature-based statistical methods, variance retention, and rapid convergence, sometimes with hybrid or ensemble learning.<br>2) Child differences: Emphasis on variance-based feature selection, batch processing, or specialized feature engineering.",
            "index": [
              "P53cfb6e5",
              "P10669016"
            ],
            "children": [
              {
                "name": "P53cfb6e5",
                "content": "BatchER.md: BatchER introduces a structured workflow for entity resolution, focusing on batch processing, variance-based feature extraction, and rapid model convergence, with evaluation highlighting the efficiency of dimensionality reduction and consistent high accuracy across classes.",
                "index": "P53cfb6e5",
                "children": []
              },
              {
                "name": "P10669016",
                "content": "GSMB.md: GSMB employs supervised meta-blocking and statistical feature engineering for entity resolution, integrating experimental data collection, normalization, and variance-based feature extraction, followed by iterative model training and evaluation to maximize predictive robustness and scalability.",
                "index": "P10669016",
                "children": []
              }
            ]
          }
        ]
      },
      {
        "name": "Systematic Blocking and Candidate Pair Reduction",
        "content": "1) Grouping feature: Methods primarily designed to reduce the computational complexity of entity resolution via systematic blocking, feature selection, or distributed candidate pruning.<br>2) Child differences: Key technique familyâ€”Distributed/Parallel Blocking Systems, Feature-based Blocking Optimization, or Hyperparameter Tuning.",
        "index": [
          "P9f0c2daf"
        ],
        "children": [
          {
            "name": "Distributed Feature-based Blocking with Hyperparameter Tuning",
            "content": "1) Grouping feature: Distributed systems for blocking, integrating automatic feature selection and hyperparameter optimization to reduce candidate space for entity matching.<br>2) Child differences: Specific workflow structures such as top-k blocking, attribute/tokenizer selection, and parameter grid search.",
            "index": [
              "P9f0c2daf"
            ],
            "children": [
              {
                "name": "P9f0c2daf",
                "content": "Sparkly.md: Sparkly implements a distributed, feature-based blocking system for entity matching, utilizing Lucene and Spark to perform top-k tf/idf blocking, automatic attribute and tokenizer selection, and hyperparameter tuning to maximize recall while minimizing computational overhead.",
                "index": "P9f0c2daf",
                "children": []
              }
            ]
          }
        ]
      }
    ]
  }
}