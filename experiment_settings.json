{
  "metadata": {
    "num_papers": 14,
    "papers_processed": [
      "f32a10ff",
      "53cfb6e5",
      "79bc4b32",
      "baa3b0fc",
      "54593c94",
      "b24a912c",
      "d6c37522",
      "9f0c2daf",
      "10669016",
      "3e96d15e",
      "6ab21388",
      "ec4709c1",
      "256e52ab",
      "07e4e216"
    ],
    "generator": "ExperimentSettingExtractor",
    "total_datasets": 48,
    "total_metrics": 13,
    "total_baselines": 90
  },
  "paper_experiments": [
    {
      "paper_id": "f32a10ff",
      "paper_title": "Low-resource Deep Entity Resolution with Transfer and Active Learning",
      "proposed_method_name": "Deep Transfer Active Learning (DTAL)",
      "datasets": [
        {
          "name": "DBLP-ACM",
          "description": "Citation dataset used for entity resolution experiments.",
          "task_type": [
            "entity matching"
          ],
          "processing": "Feature-based blocking and random splits; tokenized with NLTK and lowercased.",
          "confidence": 0.98
        },
        {
          "name": "DBLP-Scholar",
          "description": "Citation dataset for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "processing": "Feature-based blocking and random splits; tokenized with NLTK and lowercased.",
          "confidence": 0.98
        },
        {
          "name": "Cora",
          "description": "Citation dataset with 8 attributes in the schema; entity matching task.",
          "task_type": [
            "entity matching"
          ],
          "processing": "Candidate set of 50,000 pairs randomly sampled from jaccard similarity-based blocking.",
          "confidence": 0.98
        },
        {
          "name": "Fodors-Zagats",
          "description": "Restaurant dataset for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "processing": "Feature-based blocking and random splits; tokenized and lowercased.",
          "confidence": 0.9
        },
        {
          "name": "Amazon-Google",
          "description": "Product matching dataset.",
          "task_type": [
            "entity matching"
          ],
          "processing": "Feature-based blocking and random splits; tokenized and lowercased.",
          "confidence": 0.85
        },
        {
          "name": "Zomato-Yelp",
          "description": "Restaurant dataset constructed by merging Restaurants 1 and 2 from Das et al. (2016); schemas differ slightly.",
          "task_type": [
            "entity matching"
          ],
          "processing": "Null value for zip code attribute in Restaurants 1 to avoid merging errors.",
          "confidence": 0.9
        }
      ],
      "metrics": [
        {
          "name": "Precision",
          "description": "Fraction of correctly predicted positive pairs among all predicted positive pairs.",
          "confidence": 0.95
        },
        {
          "name": "Recall",
          "description": "Fraction of correctly predicted positive pairs among all actual positive pairs.",
          "confidence": 0.95
        },
        {
          "name": "F1",
          "description": "Harmonic mean of precision and recall.",
          "formulation": "F1 = 2 * (precision * recall) / (precision + recall)",
          "confidence": 0.98
        }
      ],
      "baselines": [
        {
          "name": "Deep Learning (DL)",
          "description": "Deep learning model for entity resolution using deepmatcher library.",
          "category": "deep learning",
          "citation_number": null,
          "confidence": 0.95
        },
        {
          "name": "Deep Active Learning (DAL)",
          "description": "Active learning framework with deep models (random initialization).",
          "category": "deep learning",
          "citation_number": null,
          "confidence": 0.9
        },
        {
          "name": "Support Vector Machine (SVM)",
          "description": "Non-deep learning baseline using SVM algorithm from Magellan package.",
          "category": "classical ML",
          "citation_number": "[Konda et al., 2016]",
          "confidence": 0.95
        },
        {
          "name": "Decision Tree",
          "description": "Non-deep learning baseline from Magellan package.",
          "category": "classical ML",
          "citation_number": "[Konda et al., 2016]",
          "confidence": 0.9
        },
        {
          "name": "Random Forest",
          "description": "Non-deep learning baseline from Magellan package.",
          "category": "classical ML",
          "citation_number": "[Konda et al., 2016]",
          "confidence": 0.9
        },
        {
          "name": "Naive Bayes",
          "description": "Non-deep learning baseline from Magellan package.",
          "category": "classical ML",
          "citation_number": "[Konda et al., 2016]",
          "confidence": 0.9
        },
        {
          "name": "Logistic Regression",
          "description": "Non-deep learning baseline from Magellan package.",
          "category": "classical ML",
          "citation_number": "[Konda et al., 2016]",
          "confidence": 0.9
        },
        {
          "name": "Linear Regression",
          "description": "Non-deep learning baseline from Magellan package.",
          "category": "classical ML",
          "citation_number": "[Konda et al., 2016]",
          "confidence": 0.88
        },
        {
          "name": "Mudgal et al. (2018)",
          "description": "State-of-the-art deep learning method for entity resolution.",
          "category": "deep learning",
          "citation_number": "[Mudgal et al., 2018]",
          "confidence": 0.95
        }
      ],
      "results": [
        {
          "dataset_name": "DBLP-ACM",
          "metric_name": "F1",
          "value": 0.9789,
          "provenance": {
            "quote": "DTAL | 400 | 97.89_{\\pm0.33}",
            "source": "Table 4"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DBLP-Scholar",
          "metric_name": "F1",
          "value": 0.8954,
          "provenance": {
            "quote": "DTAL | 1000 | 89.54_{\\pm0.39}",
            "source": "Table 4"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Cora",
          "metric_name": "F1",
          "value": 0.9768,
          "provenance": {
            "quote": "DTAL | 1000 | 97.68_{\\pm0.39}",
            "source": "Table 4"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Fodors-Zagats",
          "metric_name": "F1",
          "value": null,
          "provenance": {
            "quote": "only 100 active learning labels are needed to achieve the same performance as the model trained with all target labels (894 labels)",
            "source": "text/Table 5"
          },
          "confidence": 0.6
        }
      ]
    },
    {
      "paper_id": "53cfb6e5",
      "paper_title": "Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration",
      "proposed_method_name": "BATCHER",
      "datasets": [
        {
          "name": "WA",
          "description": "Part of Magellan benchmark; contains entities from two tables with labeled matching/non-matching entity pairs.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "AB",
          "description": "Part of Magellan benchmark; contains entities from two tables with labeled matching/non-matching entity pairs.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "AG",
          "description": "Amazon-Google: software products from Amazon and Google with three attributes (title, manufacturer, price); 11,460 entity pairs, 1,167 matches.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 1.0
        },
        {
          "name": "DS",
          "description": "Part of Magellan benchmark; contains entities from two tables with labeled matching/non-matching entity pairs.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "DA",
          "description": "Part of Magellan benchmark; contains entities from two tables with labeled matching/non-matching entity pairs.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "FZ",
          "description": "Part of Magellan benchmark; contains entities from two tables with labeled matching/non-matching entity pairs.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "IA",
          "description": "Part of Magellan benchmark; contains entities from two tables with labeled matching/non-matching entity pairs.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "Beer",
          "description": "Part of Magellan benchmark; small dataset with only 91 pairs for testing.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        }
      ],
      "metrics": [
        {
          "name": "F1",
          "description": "Harmonic mean of Precision and Recall, measuring matching accuracy of entity resolution.",
          "formulation": "\\mathrm{F}1 = 2 \\cdot \\mathrm{P} \\cdot \\mathrm{R} / (\\mathrm{P} + \\mathrm{R})",
          "confidence": 1.0
        },
        {
          "name": "API Cost",
          "description": "Monetary cost for API calls to LLMs, measured in US dollars.",
          "confidence": 0.95
        },
        {
          "name": "Labeling Cost",
          "description": "Monetary cost for labeling entity pairs to prepare demonstrations, estimated from crowdsourcing rates.",
          "confidence": 0.9
        }
      ],
      "baselines": [
        {
          "name": "Ditto",
          "description": "PLM-based entity resolution using RoBerta and fine-tuning on labeled pairs.",
          "category": "deep learning",
          "citation_number": "[1]",
          "confidence": 1.0
        },
        {
          "name": "JointBert",
          "description": "Dual-objective BERT model combining binary matching and multi-class classification for entity matching.",
          "category": "deep learning",
          "citation_number": "[2]",
          "confidence": 1.0
        },
        {
          "name": "RobEM",
          "description": "Robust PLM-based ER method addressing data imbalance with modifications to enhance PLMs.",
          "category": "deep learning",
          "citation_number": "[3]",
          "confidence": 1.0
        },
        {
          "name": "ManualPrompt",
          "description": "LLM-based ER (GPT-3) using manually designed prompts and demonstrations; standard prompting.",
          "category": "LLM",
          "citation_number": "[11]",
          "confidence": 1.0
        }
      ],
      "results": [
        {
          "dataset_name": "WA",
          "metric_name": "F1",
          "value": 0.8066,
          "provenance": {
            "quote": "WA | F1 | ... | 80.66 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AB",
          "metric_name": "F1",
          "value": 0.8838,
          "provenance": {
            "quote": "AB | F1 | ... | 88.38 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AG",
          "metric_name": "F1",
          "value": 0.6216,
          "provenance": {
            "quote": "AG | F1 | ... | 62.16 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DS",
          "metric_name": "F1",
          "value": 0.837,
          "provenance": {
            "quote": "DS | F1 | ... | 83.70 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DA",
          "metric_name": "F1",
          "value": 0.9496,
          "provenance": {
            "quote": "DA | F1 | ... | 94.96 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "FZ",
          "metric_name": "F1",
          "value": 1.0,
          "provenance": {
            "quote": "FZ | F1 | ... | 100.00 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "IA",
          "metric_name": "F1",
          "value": 0.9643,
          "provenance": {
            "quote": "IA | F1 | ... | 96.43 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Beer",
          "metric_name": "F1",
          "value": 0.9655,
          "provenance": {
            "quote": "Beer | F1 | ... | 96.55 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "WA",
          "metric_name": "API Cost",
          "value": 0.28,
          "provenance": {
            "quote": "WA | API ($) | ... | 0.28 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AB",
          "metric_name": "API Cost",
          "value": 0.2,
          "provenance": {
            "quote": "AB | API ($) | ... | 0.20 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AG",
          "metric_name": "API Cost",
          "value": 0.25,
          "provenance": {
            "quote": "AG | API ($) | ... | 0.25 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DS",
          "metric_name": "API Cost",
          "value": 1.12,
          "provenance": {
            "quote": "DS | API ($) | ... | 1.12 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DA",
          "metric_name": "API Cost",
          "value": 0.53,
          "provenance": {
            "quote": "DA | API ($) | ... | 0.53 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "FZ",
          "metric_name": "API Cost",
          "value": 0.03,
          "provenance": {
            "quote": "FZ | API ($) | ... | 0.03 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "IA",
          "metric_name": "API Cost",
          "value": 0.01,
          "provenance": {
            "quote": "IA | API ($) | ... | 0.01 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Beer",
          "metric_name": "API Cost",
          "value": 0.01,
          "provenance": {
            "quote": "Beer | API ($) | ... | 0.01 | ... (Table IV, Diversity-based Question Batching + Covering-based Demonstration Selection)",
            "source": "Table IV"
          },
          "confidence": 0.98
        }
      ]
    },
    {
      "paper_id": "79bc4b32",
      "paper_title": "Analyzing How BERT Performs Entity Matching",
      "proposed_method_name": "Fine-tuned BERT-based EM model",
      "datasets": [
        {
          "name": "S-FZ",
          "description": "Structured, Fodors-Zagats dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "S-DG",
          "description": "Structured, DBLP-GoogleScholar dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "S-DA",
          "description": "Structured, DBLP-ACM dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "S-AG",
          "description": "Structured, Amazon-Google dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "S-WA",
          "description": "Structured, Walmart-Amazon dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "S-BR",
          "description": "Structured, BeerAdvo-RateBeer dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "S-IA",
          "description": "Structured, iTunes-Amazon dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "T-AB",
          "description": "Textual, Abt-Buy dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "D-IA",
          "description": "Dirty, iTunes-Amazon dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "D-DA",
          "description": "Dirty, DBLP-ACM dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "D-DG",
          "description": "Dirty, DBLP-GoogleScholar dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        },
        {
          "name": "D-WA",
          "description": "Dirty, Walmart-Amazon dataset from Magellan Benchmark",
          "task_type": [
            "entity matching"
          ],
          "processing": "Pairs of entity descriptions, split into train, validation, and test sets in 60/20/20 proportion; balanced samples for analysis; attributes concatenated or separated by [SEP] token.",
          "confidence": 0.98
        }
      ],
      "metrics": [
        {
          "name": "F1 score",
          "description": "Harmonic mean of precision and recall for the binary classification of matching vs. non-matching entities.",
          "confidence": 0.98
        }
      ],
      "baselines": [
        {
          "name": "DM+",
          "description": "DeepMatcher+, a reference DL-based EM approach that does not rely on a transformer architecture.",
          "category": "deep learning",
          "citation_number": "[21]",
          "confidence": 0.95
        },
        {
          "name": "Ditto",
          "description": "A BERT-based EM approach with data augmentation techniques and advanced EM data encoding.",
          "category": "deep learning",
          "citation_number": "[17]",
          "confidence": 0.97
        }
      ],
      "results": [
        {
          "dataset_name": "S-FZ",
          "metric_name": "F1 score",
          "value": 1.0,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 100.00; Fine-tuned (sent-pair): 97.67",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "S-DG",
          "metric_name": "F1 score",
          "value": 0.9492,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 94.92; Fine-tuned (sent-pair): 94.78",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "S-DA",
          "metric_name": "F1 score",
          "value": 0.9842,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 98.42; Fine-tuned (sent-pair): 98.65",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "S-AG",
          "metric_name": "F1 score",
          "value": 0.7021,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 70.21; Fine-tuned (sent-pair): 68.52",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "S-WA",
          "metric_name": "F1 score",
          "value": 0.7979,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 79.79; Fine-tuned (sent-pair): 78.85",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "S-BR",
          "metric_name": "F1 score",
          "value": 0.8485,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 77.78; Fine-tuned (sent-pair): 84.85",
            "source": "Table 2"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "S-IA",
          "metric_name": "F1 score",
          "value": 0.931,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 90.00; Fine-tuned (sent-pair): 93.10",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "T-AB",
          "metric_name": "F1 score",
          "value": 0.8351,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 81.42; Fine-tuned (sent-pair): 83.51",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "D-IA",
          "metric_name": "F1 score",
          "value": 0.9474,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 94.74; Fine-tuned (sent-pair): 94.74",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "D-DA",
          "metric_name": "F1 score",
          "value": 0.9843,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 98.43; Fine-tuned (sent-pair): 98.42",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "D-DG",
          "metric_name": "F1 score",
          "value": 0.9507,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 95.07; Fine-tuned (sent-pair): 94.77",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "D-WA",
          "metric_name": "F1 score",
          "value": 0.7959,
          "provenance": {
            "quote": "Fine-tuned (attr-pair): 79.59; Fine-tuned (sent-pair): 77.33",
            "source": "Table 2"
          },
          "confidence": 0.97
        }
      ]
    },
    {
      "paper_id": "baa3b0fc",
      "paper_title": "CollaborER: A Self-supervised Entity Resolution Framework Using Multi-features Collaboration",
      "proposed_method_name": "CollaborER",
      "datasets": [
        {
          "name": "AG",
          "description": "Amazon-Google; software domain, structured ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "BR",
          "description": "BeerAdvo-RateBeer; beer domain, structured ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "DA-clean",
          "description": "clean version of DBLP-ACM; citation domain, structured ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "FZ",
          "description": "Fodors-Zagats; restaurant domain, structured ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "IA-clean",
          "description": "clean version of iTunes-Amazon; music domain, structured ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "DA-dirty",
          "description": "dirty version of DBLP-ACM; citation domain, dirty ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "IA-dirty",
          "description": "dirty version of iTunes-Amazon; music domain, dirty ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "AB",
          "description": "Abt-Buy; product domain, text-heavy ER benchmark",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        }
      ],
      "metrics": [
        {
          "name": "F1-score",
          "description": "Harmonic mean of precision and recall; measures ER quality",
          "formulation": "\\frac{2 \\times (\\text{Prec.} \\times \\text{Rec.})}{(\\text{Prec.} + \\text{Rec.})}",
          "confidence": 0.99
        }
      ],
      "baselines": [
        {
          "name": "ZeroER",
          "description": "Unsupervised, generative ER approach using Gaussian Mixture Models",
          "category": "unsupervised",
          "citation_number": "[46]",
          "confidence": 0.95
        },
        {
          "name": "EMBDI",
          "description": "Unsupervised, learns local embeddings for ER based on attribute-centric graphs",
          "category": "unsupervised",
          "citation_number": "[5]",
          "confidence": 0.95
        },
        {
          "name": "DeepMatcher+ (DM+)",
          "description": "Supervised, implements multiple ER methods and reports best F1-scores",
          "category": "deep learning",
          "citation_number": "[25]",
          "confidence": 0.95
        },
        {
          "name": "GraphER",
          "description": "Supervised, integrates schematic and structural information with GNN for ER",
          "category": "graph",
          "citation_number": "[23]",
          "confidence": 0.95
        },
        {
          "name": "MCA",
          "description": "Supervised, uses attention mechanism in sequence-based model for ER",
          "category": "deep learning",
          "citation_number": "[50]",
          "confidence": 0.95
        },
        {
          "name": "ERGAN",
          "description": "Supervised, generative adversarial network for label augmentation in ER",
          "category": "deep learning",
          "citation_number": "[36]",
          "confidence": 0.95
        },
        {
          "name": "DITTO",
          "description": "Supervised, pre-trained Transformer-based language model for ER as sentence-pair classification",
          "category": "transformer",
          "citation_number": "[25]",
          "confidence": 0.95
        },
        {
          "name": "DITTO-S",
          "description": "DITTO using pseudo labels generated by CollaborER's ALG",
          "category": "transformer",
          "citation_number": "[25]",
          "confidence": 0.9
        }
      ],
      "results": [
        {
          "dataset_name": "AG",
          "metric_name": "F1-score",
          "value": 0.6861,
          "provenance": {
            "quote": "CollaborER-U: 68.61",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "AG",
          "metric_name": "F1-score",
          "value": 0.7191,
          "provenance": {
            "quote": "CollaborER-S: 71.91",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "BR",
          "metric_name": "F1-score",
          "value": 0.8769,
          "provenance": {
            "quote": "CollaborER-U: 87.69",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "BR",
          "metric_name": "F1-score",
          "value": 0.9655,
          "provenance": {
            "quote": "CollaborER-S: 96.55",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DA-clean",
          "metric_name": "F1-score",
          "value": 0.9863,
          "provenance": {
            "quote": "CollaborER-U: 98.63",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DA-clean",
          "metric_name": "F1-score",
          "value": 0.9865,
          "provenance": {
            "quote": "CollaborER-S: 98.65",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "FZ",
          "metric_name": "F1-score",
          "value": 1.0,
          "provenance": {
            "quote": "CollaborER-U: 100",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "FZ",
          "metric_name": "F1-score",
          "value": 1.0,
          "provenance": {
            "quote": "CollaborER-S: 100",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "IA-clean",
          "metric_name": "F1-score",
          "value": 0.9612,
          "provenance": {
            "quote": "CollaborER-U: 96.12",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "IA-clean",
          "metric_name": "F1-score",
          "value": 1.0,
          "provenance": {
            "quote": "CollaborER-S: 100",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DA-dirty",
          "metric_name": "F1-score",
          "value": 0.9825,
          "provenance": {
            "quote": "CollaborER-U: 98.25",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DA-dirty",
          "metric_name": "F1-score",
          "value": 0.991,
          "provenance": {
            "quote": "CollaborER-S: 99.10",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "IA-dirty",
          "metric_name": "F1-score",
          "value": 0.9517,
          "provenance": {
            "quote": "CollaborER-U: 95.17",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "IA-dirty",
          "metric_name": "F1-score",
          "value": 0.9818,
          "provenance": {
            "quote": "CollaborER-S: 98.18",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "AB",
          "metric_name": "F1-score",
          "value": 0.8317,
          "provenance": {
            "quote": "CollaborER-U: 83.17",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "AB",
          "metric_name": "F1-score",
          "value": 0.8501,
          "provenance": {
            "quote": "CollaborER-S: 85.01",
            "source": "Table 3"
          },
          "confidence": 0.99
        }
      ]
    },
    {
      "paper_id": "54593c94",
      "paper_title": "Blocker and Matcher Can Mutually Benefit: A Co-Learning Framework for Low-Resource Entity Resolution",
      "proposed_method_name": "CLER",
      "datasets": [
        {
          "name": "Amazon-Google (AG)",
          "description": "Product matching dataset from the Magellan repository for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "DBLP-ACM (DA)",
          "description": "Bibliographic dataset from the Magellan repository for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "DBLP-Scholar (DS)",
          "description": "Bibliographic dataset from the Magellan repository for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Fodors-Zagats (FZ)",
          "description": "Restaurant matching dataset from the Magellan repository for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Walmart-Amazon (WA)",
          "description": "Product matching dataset from the Magellan repository for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Abt-Buy (AB)",
          "description": "Product matching dataset from the Magellan repository for entity resolution.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Monitor (M)",
          "description": "A dataset from the Alaska benchmark for entity matching.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        }
      ],
      "metrics": [
        {
          "name": "F1-score",
          "description": "Harmonic mean of precision and recall for entity matching.",
          "formulation": null,
          "confidence": 0.98
        },
        {
          "name": "Recall",
          "description": "Proportion of true matches correctly identified by the blocker.",
          "confidence": 0.9
        }
      ],
      "baselines": [
        {
          "name": "CollaborEM",
          "description": "Unsupervised framework that constructs rule-based pseudo labels and combines graph and sentence features.",
          "category": "unsupervised",
          "citation_number": "[12]",
          "confidence": 0.95
        },
        {
          "name": "DITTO",
          "description": "Supervised ER model; fine-tunes a pre-trained language model for sentence-pair classification.",
          "category": "deep learning",
          "citation_number": "[18]",
          "confidence": 0.95
        },
        {
          "name": "DTAL",
          "description": "Iterative active-learning-based entity matching method allocating annotation budget to informative pairs.",
          "category": "active learning",
          "citation_number": "[15]",
          "confidence": 0.95
        },
        {
          "name": "DITTO-full",
          "description": "DITTO trained with the full training data of the processed Magellan datasets.",
          "category": "deep learning",
          "confidence": 0.9
        },
        {
          "name": "LLaMA-65B",
          "description": "Large language model (65B) with 10-shot in-context learning.",
          "category": "LLM",
          "citation_number": "[32]",
          "confidence": 0.92
        },
        {
          "name": "GPT3-175B",
          "description": "Large language model (175B parameters) with 10-shot in-context learning.",
          "category": "LLM",
          "citation_number": "[4]",
          "confidence": 0.92
        },
        {
          "name": "SBERT",
          "description": "Pre-trained SBERT used as a blocker.",
          "category": "deep learning",
          "citation_number": "[30]",
          "confidence": 0.9
        },
        {
          "name": "DeepBlocker",
          "description": "Blocker baseline for candidate generation.",
          "category": "deep learning",
          "citation_number": "[31]",
          "confidence": 0.9
        },
        {
          "name": "Sudowoodo",
          "description": "Blocker baseline for candidate generation.",
          "category": "deep learning",
          "citation_number": "[35]",
          "confidence": 0.9
        }
      ],
      "results": [
        {
          "dataset_name": "Amazon-Google (AG)",
          "metric_name": "F1-score",
          "value": 0.7765,
          "provenance": {
            "quote": "CLER | 77.65",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DBLP-ACM (DA)",
          "metric_name": "F1-score",
          "value": 0.989,
          "provenance": {
            "quote": "CLER | 98.90",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DBLP-Scholar (DS)",
          "metric_name": "F1-score",
          "value": 0.9365,
          "provenance": {
            "quote": "CLER | 93.65",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Fodors-Zagats (FZ)",
          "metric_name": "F1-score",
          "value": 0.9754,
          "provenance": {
            "quote": "CLER | 97.54",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Walmart-Amazon (WA)",
          "metric_name": "F1-score",
          "value": 0.8848,
          "provenance": {
            "quote": "CLER | 88.48",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Abt-Buy (AB)",
          "metric_name": "F1-score",
          "value": 0.9584,
          "provenance": {
            "quote": "CLER | 95.84",
            "source": "Table 2"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Monitor (M)",
          "metric_name": "F1-score",
          "value": 0.7184,
          "provenance": {
            "quote": "our CLER achieves 71.84% F1-score with only an annotation budget of 500",
            "source": "text"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Amazon-Google (AG)",
          "metric_name": "Recall",
          "value": 0.9812,
          "provenance": {
            "quote": "CLER | Recall | 98.12",
            "source": "Table 6"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "Walmart-Amazon (WA)",
          "metric_name": "Recall",
          "value": 0.9845,
          "provenance": {
            "quote": "CLER | Recall | 98.45",
            "source": "Table 6"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "Monitor (M)",
          "metric_name": "Recall",
          "value": 0.9643,
          "provenance": {
            "quote": "CLER | Recall | 96.43",
            "source": "Table 6"
          },
          "confidence": 0.9
        }
      ]
    },
    {
      "paper_id": "b24a912c",
      "paper_title": "In-context Clustering-based Entity Resolution with Large Language Models: A Design Space Exploration",
      "proposed_method_name": "LLM-CER",
      "datasets": [
        {
          "name": "Cora",
          "description": "A text-based dataset comprising duplicate references to scientific publications; structured CSV version used.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.99
        },
        {
          "name": "Alaska",
          "description": "An e-commerce product dataset collected from multiple websites.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "AS",
          "description": "Widely recognized for Dirty ER benchmarks.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "DBLP-Google",
          "description": "Citation domain dataset containing bibliographic duplicates sourced from DBLP and Google Scholar.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.92
        },
        {
          "name": "Citeseer-DBLP",
          "description": "Citation domain dataset containing bibliographic duplicates sourced from Citeseer and DBLP.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.92
        },
        {
          "name": "Song",
          "description": "Music domain dataset including information from various platforms.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "Music",
          "description": "Music 20K dataset, used for Dirty ER benchmarks; large-scale variants up to 50K records.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "AmazonGoogle",
          "description": "Dataset from the Software domain, more specialized and complex ER tasks.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.94
        },
        {
          "name": "Walmart-Amazon",
          "description": "Dataset from the Electronics domain, more specialized and complex ER tasks.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.94
        }
      ],
      "metrics": [
        {
          "name": "Accuracy",
          "description": "Proportion of correctly clustered records according to the ground truth clusters.",
          "formulation": "\\mathrm{ACC}=\\frac{\\text { CorrectCount }}{|\\Re|} \\quad \\text { CorrectCount }=\\sum_{X_{j} \\in \\mathbb{X}} \\sum_{x \\in X_{j}} \\mathbb{I}(\\exists y \\in M_{j}^{\\prime}, y=x)",
          "confidence": 0.99
        },
        {
          "name": "FP-measure",
          "description": "Harmonic mean of purity and inverse-purity, evaluating clustering homogeneity and stability.",
          "formulation": "\\text{FP-measure}(\\mathbb{X}, \\forall)=\\frac{2}{1/\\text{purity}(\\mathbb{X}, \\forall)+1/\\text{inverse-purity}(\\mathbb{X}, \\forall)}",
          "confidence": 0.99
        }
      ],
      "baselines": [
        {
          "name": "Booster",
          "description": "LLM-based ER method employing traditional blocking and iterative partition scoring.",
          "category": "LLM",
          "citation_number": "[43]",
          "confidence": 0.98
        },
        {
          "name": "BQ",
          "description": "Batch-Questioning: Batches pairwise match questions into a single prompt for LLMs.",
          "category": "LLM",
          "citation_number": "[26]",
          "confidence": 0.98
        },
        {
          "name": "CrowdER+LLM",
          "description": "Clustering-based design that filters irrelevant pairs and uses LLM to cluster ambiguous cases.",
          "category": "LLM",
          "citation_number": "[77]",
          "confidence": 0.97
        }
      ],
      "results": [
        {
          "dataset_name": "Alaska",
          "metric_name": "Accuracy",
          "value": 0.82,
          "provenance": {
            "quote": "Alaska | ACC | 0.82 | 0.71 | 0.33 | 0.68",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Alaska",
          "metric_name": "FP-measure",
          "value": 0.79,
          "provenance": {
            "quote": "Alaska | FP | 0.79 | 0.55 | 0.49 | 0.62",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "AS",
          "metric_name": "Accuracy",
          "value": 0.7,
          "provenance": {
            "quote": "AS | ACC | 0.70 | 0.62 | 0.54 | 0.52",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "AS",
          "metric_name": "FP-measure",
          "value": 0.63,
          "provenance": {
            "quote": "AS | FP | 0.63 | 0.62 | 0.51 | 0.50",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Song",
          "metric_name": "Accuracy",
          "value": 0.72,
          "provenance": {
            "quote": "Song | ACC | 0.72 | 0.52 | 0.59 | 0.52",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Song",
          "metric_name": "FP-measure",
          "value": 0.78,
          "provenance": {
            "quote": "Song | FP | 0.78 | 0.68 | 0.67 | 0.64",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Music",
          "metric_name": "Accuracy",
          "value": 0.71,
          "provenance": {
            "quote": "Music | ACC | 0.71 | 0.59 | 0.60 | 0.62",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Music",
          "metric_name": "FP-measure",
          "value": 0.61,
          "provenance": {
            "quote": "Music | FP | 0.61 | 0.60 | 0.54 | 0.55",
            "source": "Table 4"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DG",
          "metric_name": "Accuracy",
          "value": 0.81,
          "provenance": {
            "quote": "DG | ACC | 0.81 | 0.56 | 0.62 | 0.72",
            "source": "Table 4"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DG",
          "metric_name": "FP-measure",
          "value": 0.7,
          "provenance": {
            "quote": "DG | FP | 0.70 | 0.68 | 0.63 | 0.65",
            "source": "Table 4"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Cora",
          "metric_name": "Accuracy",
          "value": 0.9,
          "provenance": {
            "quote": "Cora | ACC | 0.90 | 0.75 | 0.62 | 0.51",
            "source": "Table 4"
          },
          "confidence": 1.0
        },
        {
          "dataset_name": "Cora",
          "metric_name": "FP-measure",
          "value": 0.71,
          "provenance": {
            "quote": "Cora | FP | 0.71 | 0.60 | 0.56 | 0.61",
            "source": "Table 4"
          },
          "confidence": 1.0
        },
        {
          "dataset_name": "Citeseer",
          "metric_name": "Accuracy",
          "value": 0.88,
          "provenance": {
            "quote": "Citeseer | ACC | 0.88 | 0.72 | 0.64 | 0.60",
            "source": "Table 4"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "Citeseer",
          "metric_name": "FP-measure",
          "value": 0.95,
          "provenance": {
            "quote": "Citeseer | FP | 0.95 | 0.78 | 0.79 | 0.69",
            "source": "Table 4"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AmazonGoogle",
          "metric_name": "Accuracy",
          "value": 0.71,
          "provenance": {
            "quote": "AmazonGoogle | ACC | 0.71 | 0.58 | 0.53 | 0.50",
            "source": "Table 4"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "AmazonGoogle",
          "metric_name": "FP-measure",
          "value": 0.64,
          "provenance": {
            "quote": "AmazonGoogle | FP | 0.64 | 0.55 | 0.50 | 0.48",
            "source": "Table 4"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Walmart-Amazon",
          "metric_name": "Accuracy",
          "value": 0.61,
          "provenance": {
            "quote": "WalmartAmazon | ACC | 0.61 | 0.50 | 0.42 | 0.51",
            "source": "Table 4"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Walmart-Amazon",
          "metric_name": "FP-measure",
          "value": 0.56,
          "provenance": {
            "quote": "WalmartAmazon | FP | 0.56 | 0.48 | 0.41 | 0.50",
            "source": "Table 4"
          },
          "confidence": 0.97
        }
      ]
    },
    {
      "paper_id": "d6c37522",
      "paper_title": "PromptEM: Prompt-tuning for Low-resource Generalized Entity Matching",
      "proposed_method_name": "PromptEM",
      "datasets": [
        {
          "name": "REL-HETER",
          "description": "Relational, heterogeneous schema entity matching dataset from Machamp",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.93
        },
        {
          "name": "SEMI-HOMO",
          "description": "Semi-structured, homogeneous schema entity matching dataset from Machamp",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.93
        },
        {
          "name": "SEMI-HETER",
          "description": "Semi-structured, heterogeneous schema entity matching dataset from Machamp",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.93
        },
        {
          "name": "SEMI-REL",
          "description": "Semi-structured and relational entity matching dataset from Machamp",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.93
        },
        {
          "name": "SEMI-TEXT-c",
          "description": "Semi-structured and textual entity matching dataset (category) from Machamp",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.92
        },
        {
          "name": "SEMI-TEXT-w",
          "description": "Semi-structured and textual entity matching dataset (word) from Machamp",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.92
        },
        {
          "name": "REL-TEXT",
          "description": "Relational and textual entity matching dataset from Machamp",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.93
        },
        {
          "name": "GEO-HETER",
          "description": "Geospatial heterogeneous entity matching dataset",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.93
        }
      ],
      "metrics": [
        {
          "name": "Precision",
          "description": "Proportion of predicted matches that are correct",
          "formulation": null,
          "confidence": 0.95
        },
        {
          "name": "Recall",
          "description": "Proportion of ground-truth matches that are predicted",
          "formulation": null,
          "confidence": 0.95
        },
        {
          "name": "F1-score",
          "description": "Harmonic mean of precision and recall",
          "formulation": null,
          "confidence": 0.95
        }
      ],
      "baselines": [
        {
          "name": "DeepMatcher",
          "description": "Entity matching framework using RNNs to aggregate attribute values",
          "category": "deep learning",
          "citation_number": "[31]",
          "confidence": 0.95
        },
        {
          "name": "BERT",
          "description": "Fine-tuned for entity matching as a sequence pair classification task",
          "category": "deep learning",
          "citation_number": "[6]",
          "confidence": 0.95
        },
        {
          "name": "SentenceBERT",
          "description": "Siamese architecture for pretrained LMs for sentence/entity matching",
          "category": "deep learning",
          "citation_number": "[36]",
          "confidence": 0.95
        },
        {
          "name": "Ditto",
          "description": "State-of-the-art EM approach using pre-trained LM with domain knowledge, TF-IDF summarization, and data augmentation",
          "category": "deep learning",
          "citation_number": "[23]",
          "confidence": 0.95
        },
        {
          "name": "DADER",
          "description": "Transfer learning-based EM framework via domain adaptation",
          "category": "deep learning",
          "citation_number": "[45]",
          "confidence": 0.95
        },
        {
          "name": "Rotom",
          "description": "Meta-learning framework for data selection/weighting to better fine-tune LMs",
          "category": "deep learning",
          "citation_number": "[30]",
          "confidence": 0.95
        },
        {
          "name": "TDmatch",
          "description": "Unsupervised approach using graph creation and random walk for structured/text data",
          "category": "graph-based, unsupervised",
          "citation_number": "[1]",
          "confidence": 0.95
        },
        {
          "name": "TDmatch*",
          "description": "TDmatch embeddings with an MLP classifier in supervised setting",
          "category": "deep learning",
          "confidence": 0.9
        }
      ],
      "results": [
        {
          "dataset_name": "REL-HETER",
          "metric_name": "F1-score",
          "value": 1.0,
          "provenance": {
            "quote": "PromptEM | 100 | 100 | 100",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-HOMO",
          "metric_name": "F1-score",
          "value": 0.942,
          "provenance": {
            "quote": "PromptEM | 94.2 | 94.1 | 94.2",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-HETER",
          "metric_name": "F1-score",
          "value": 0.716,
          "provenance": {
            "quote": "PromptEM | 93.9 | 57.9 | 71.6",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-REL",
          "metric_name": "F1-score",
          "value": 0.95,
          "provenance": {
            "quote": "PromptEM | 91.4 | 98.9 | 95.0",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-TEXT-c",
          "metric_name": "F1-score",
          "value": 0.723,
          "provenance": {
            "quote": "PromptEM | 80.6 | 65.5 | 72.3",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-TEXT-w",
          "metric_name": "F1-score",
          "value": 0.411,
          "provenance": {
            "quote": "PromptEM | 44.9 | 37.9 | 41.1",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "REL-TEXT",
          "metric_name": "F1-score",
          "value": 0.614,
          "provenance": {
            "quote": "PromptEM | 61.2 | 61.5 | 61.4",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "GEO-HETER",
          "metric_name": "F1-score",
          "value": 0.84,
          "provenance": {
            "quote": "PromptEM | 78.8 | 89.9 | 84.0",
            "source": "Table 2"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "REL-HETER",
          "metric_name": "F1-score",
          "value": 1.0,
          "provenance": {
            "quote": "PromptEM | 100 | 100 | 100",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-HOMO",
          "metric_name": "F1-score",
          "value": 0.89,
          "provenance": {
            "quote": "PromptEM | 86.1 | 92.2 | 89.0",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-HETER",
          "metric_name": "F1-score",
          "value": 0.442,
          "provenance": {
            "quote": "PromptEM | 93.9 | 28.9 | 44.2",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-REL",
          "metric_name": "F1-score",
          "value": 0.943,
          "provenance": {
            "quote": "PromptEM | 94.0 | 94.5 | 94.3",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-TEXT-c",
          "metric_name": "F1-score",
          "value": 0.339,
          "provenance": {
            "quote": "PromptEM | 40.8 | 29.0 | 33.9",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "SEMI-TEXT-w",
          "metric_name": "F1-score",
          "value": 0.236,
          "provenance": {
            "quote": "PromptEM | 15.7 | 46.9 | 23.6",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "REL-TEXT",
          "metric_name": "F1-score",
          "value": 0.347,
          "provenance": {
            "quote": "PromptEM | 26.5 | 50.2 | 34.7",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "GEO-HETER",
          "metric_name": "F1-score",
          "value": 0.799,
          "provenance": {
            "quote": "PromptEM | 78.0 | 81.9 | 79.9",
            "source": "Table 3"
          },
          "confidence": 0.99
        }
      ]
    },
    {
      "paper_id": "9f0c2daf",
      "paper_title": "Sparkly: A Simple yet Surprisingly Strong TF/IDF Blocker for Entity Matching",
      "proposed_method_name": "Sparkly",
      "datasets": [
        {
          "name": "Amazon-Google",
          "description": "Structured dataset with short atomic attributes; used for entity matching.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "AmazonGoogle_2",
          "description": "Textual version derived from structured Amazon-Google dataset with 2-3 textual blob attributes.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.9
        },
        {
          "name": "Hospital",
          "description": "Private dataset for entity matching.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.7
        },
        {
          "name": "Songs",
          "description": "Structured dataset used for entity matching, large scale experiments.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.85
        },
        {
          "name": "BC",
          "description": "Big Citations: blocks two tables of 2.5M and 1.8M paper citations, with complete gold.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "MB",
          "description": "Music Brainz: blocks a table of 20M songs (against itself), with complete gold.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "WDC",
          "description": "Web Data Commons: blocks a table of 26M product descriptions; lacks complete gold.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.9
        }
      ],
      "metrics": [
        {
          "name": "Recall",
          "description": "Fraction of true matches retained after blocking; $R=|C \\cap G| /|G|$, where $C$ is the blocking output and $G$ is the set of all gold matches.",
          "formulation": "R=|C \\cap G| /|G|",
          "confidence": 0.98
        },
        {
          "name": "Candidate Set Size Ratio",
          "description": "Ratio of candidate pairs output by the blocker to all possible pairs, $CSSR=|C| /|A \\times B|$.",
          "formulation": "CSSR=|C| /|A \\times B|",
          "confidence": 0.95
        }
      ],
      "baselines": [
        {
          "name": "Autoencoder",
          "description": "Deep learning (DL) based blocker; one of the two best DL blockers.",
          "category": "deep learning",
          "citation_number": "[38]",
          "confidence": 0.98
        },
        {
          "name": "Hybrid",
          "description": "Deep learning based blocker; one of the two best DL blockers.",
          "category": "deep learning",
          "citation_number": "[38]",
          "confidence": 0.98
        },
        {
          "name": "Union(DL,RBB)",
          "description": "Combination of the best DL blocker and RBB, a SOTA industrial blocker.",
          "category": "deep learning, industrial",
          "citation_number": "[38]",
          "confidence": 0.95
        },
        {
          "name": "PBW",
          "description": "SOTA hash blocker from JedAI open-source platform.",
          "category": "hashing",
          "citation_number": "[31, 33]",
          "confidence": 0.93
        },
        {
          "name": "DBW",
          "description": "SOTA hash blocker from JedAI open-source platform.",
          "category": "hashing",
          "citation_number": "[31, 33]",
          "confidence": 0.93
        },
        {
          "name": "JD",
          "description": "SOTA hash blocker from JedAI open-source platform.",
          "category": "hashing",
          "citation_number": "[31, 33]",
          "confidence": 0.93
        },
        {
          "name": "kNN-cosine",
          "description": "kNN blocker using cosine similarity over 5-gram tokenization.",
          "category": "heuristic",
          "citation_number": "[29]",
          "confidence": 0.9
        },
        {
          "name": "kNN-jaccard",
          "description": "kNN blocker using Jaccard similarity over 3-gram and 5-gram tokenization.",
          "category": "heuristic",
          "citation_number": "[29]",
          "confidence": 0.9
        }
      ],
      "results": [
        {
          "dataset_name": "Amazon-Google",
          "metric_name": "Recall",
          "value": 0.98,
          "provenance": {
            "quote": "at recall of $98 \\%$, Sparkly-Man achieves CSSR of $2.5 \\%$, whereas the two DL blockers achieve CSSR of $10 \\%$.",
            "source": "text"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "Amazon-Google",
          "metric_name": "Candidate Set Size Ratio",
          "value": 0.025,
          "provenance": {
            "quote": "at recall of $98 \\%$, Sparkly-Man achieves CSSR of $2.5 \\%$",
            "source": "text"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "MB",
          "metric_name": "Recall",
          "value": 0.98,
          "provenance": {
            "quote": "Sparkly achieves high recall on MB and BC at $k=50$.",
            "source": "text and Table 3: 'MB 10M' row: Recall @ 50: 94/98 (SM/SA)"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "MB",
          "metric_name": "Recall",
          "value": 0.96,
          "provenance": {
            "quote": "MB 10M: Recall @ 25: 91/98 (SM/SA)",
            "source": "Table 3"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "MB",
          "metric_name": "Recall",
          "value": 0.95,
          "provenance": {
            "quote": "MB 10M: Recall @ 10: 85/96 (SM/SA)",
            "source": "Table 3"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "BC",
          "metric_name": "Recall",
          "value": 1.0,
          "provenance": {
            "quote": "BC 2.5M: Recall @ 25: 100/89 (SM/SA); Recall @ 50: 100/94",
            "source": "Table 3"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "BC",
          "metric_name": "Recall",
          "value": 0.99,
          "provenance": {
            "quote": "BC 2.5M: Recall @ 10: 99/79 (SM/SA)",
            "source": "Table 3"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "WDC",
          "metric_name": "Recall",
          "value": null,
          "provenance": {
            "quote": "We cannot compute recall for WDC as it does not have the complete gold.",
            "source": "text"
          },
          "confidence": 0.8
        }
      ]
    },
    {
      "paper_id": "10669016",
      "paper_title": "Generalized Supervised Meta-blocking",
      "proposed_method_name": "Generalized Supervised Meta-blocking",
      "datasets": [
        {
          "name": "AbtBuy",
          "description": "Matches products extracted from Abt.com and Buy.com [18]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 1.0
        },
        {
          "name": "DblpAcm",
          "description": "Matches scientific articles extracted from dblp.org and dl.acm.org [18]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 1.0
        },
        {
          "name": "ScholarDbIp",
          "description": "Matches scientific articles extracted from scholar.google.com and dblp.org [18]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 1.0
        },
        {
          "name": "AmazonGP",
          "description": "Entity matching dataset, some duplicate entities share no infrequent attribute value token",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "ImdbTmdb",
          "description": "Matches movies and TV series extracted from IMDB and TheMovieDB [19]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "ImdbTvdb",
          "description": "Matches movies and TV series extracted from IMDB and TheTVDB [19]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "TmdbTvdb",
          "description": "Matches movies and TV series extracted from TheMovieDB and TheTVDB [19]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Movies",
          "description": "Matches information about films extracted from imdb.com and dbpedia.org [21]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "WMAmazon",
          "description": "Matches products from Walmart.com and Amazon.com [8]",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        }
      ],
      "metrics": [
        {
          "name": "Recall",
          "description": "Fraction of ground-truth matches retained after blocking and pruning",
          "confidence": 1.0
        },
        {
          "name": "Precision",
          "description": "Fraction of predicted matches that are correct",
          "confidence": 1.0
        },
        {
          "name": "F1",
          "description": "Harmonic mean of precision and recall",
          "formulation": "$F1 = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}$",
          "confidence": 1.0
        }
      ],
      "baselines": [
        {
          "name": "BCI",
          "description": "Binary classifier for weight-based supervised meta-blocking",
          "category": "classical ML",
          "citation_number": "[25]",
          "confidence": 1.0
        },
        {
          "name": "CEP",
          "description": "Cardinality-based pruning algorithm",
          "category": "heuristic",
          "citation_number": "[25]",
          "confidence": 0.8
        },
        {
          "name": "CNP",
          "description": "Cardinality-based pruning algorithm",
          "category": "heuristic",
          "citation_number": "[25]",
          "confidence": 0.9
        },
        {
          "name": "Supervised Meta-blocking",
          "description": "Original supervised meta-blocking framework using BCI and CNP with the feature set proposed in [25]",
          "category": "classical ML",
          "citation_number": "[25]",
          "confidence": 0.95
        }
      ],
      "results": [
        {
          "dataset_name": "AbtBuy",
          "metric_name": "Recall",
          "value": 0.8345,
          "provenance": {
            "quote": "Re | 0.8345",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AbtBuy",
          "metric_name": "Precision",
          "value": 0.2837,
          "provenance": {
            "quote": "Pr | 0.2837",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AbtBuy",
          "metric_name": "F1",
          "value": 0.3265,
          "provenance": {
            "quote": "F1 | 0.3265",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DblpAcm",
          "metric_name": "Recall",
          "value": 0.9511,
          "provenance": {
            "quote": "Re | 0.9511",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DblpAcm",
          "metric_name": "Precision",
          "value": 0.6509,
          "provenance": {
            "quote": "Pr | 0.6509",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DblpAcm",
          "metric_name": "F1",
          "value": 0.769,
          "provenance": {
            "quote": "F1 | 0.7690",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "ScholarDbIp",
          "metric_name": "Recall",
          "value": 0.9638,
          "provenance": {
            "quote": "Re | 0.9638",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "ScholarDbIp",
          "metric_name": "Precision",
          "value": 0.3418,
          "provenance": {
            "quote": "Pr | 0.3418",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "ScholarDbIp",
          "metric_name": "F1",
          "value": 0.4988,
          "provenance": {
            "quote": "F1 | 0.4988",
            "source": "Table 5a"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "AmazonGP",
          "metric_name": "Recall",
          "value": 0.7001,
          "provenance": {
            "quote": "Re | 0.7001",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "AmazonGP",
          "metric_name": "Precision",
          "value": 0.1441,
          "provenance": {
            "quote": "Pr | 0.1441",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "AmazonGP",
          "metric_name": "F1",
          "value": 0.2385,
          "provenance": {
            "quote": "F1 | 0.2385",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "ImdbTmdb",
          "metric_name": "Recall",
          "value": 0.8225,
          "provenance": {
            "quote": "Re | 0.8225",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "ImdbTmdb",
          "metric_name": "Precision",
          "value": 0.5756,
          "provenance": {
            "quote": "Pr | 0.5756",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "ImdbTmdb",
          "metric_name": "F1",
          "value": 0.6726,
          "provenance": {
            "quote": "F1 | 0.6726",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "ImdbTvdb",
          "metric_name": "Recall",
          "value": 0.7483,
          "provenance": {
            "quote": "Re | 0.7483",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "ImdbTvdb",
          "metric_name": "Precision",
          "value": 0.2584,
          "provenance": {
            "quote": "Pr | 0.2584",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "ImdbTvdb",
          "metric_name": "F1",
          "value": 0.3456,
          "provenance": {
            "quote": "F1 | 0.3456",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "TmdbTvdb",
          "metric_name": "Recall",
          "value": 0.8466,
          "provenance": {
            "quote": "Re | 0.8466",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "TmdbTvdb",
          "metric_name": "Precision",
          "value": 0.2477,
          "provenance": {
            "quote": "Pr | 0.2477",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "TmdbTvdb",
          "metric_name": "F1",
          "value": 0.377,
          "provenance": {
            "quote": "F1 | 0.3770",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Movies",
          "metric_name": "Recall",
          "value": 0.9151,
          "provenance": {
            "quote": "Re | 0.9151",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Movies",
          "metric_name": "Precision",
          "value": 0.15,
          "provenance": {
            "quote": "Pr | 0.1500",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Movies",
          "metric_name": "F1",
          "value": 0.2221,
          "provenance": {
            "quote": "F1 | 0.2221",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "WMAmazon",
          "metric_name": "Recall",
          "value": 0.9587,
          "provenance": {
            "quote": "Re | 0.9587",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "WMAmazon",
          "metric_name": "Precision",
          "value": 0.0025,
          "provenance": {
            "quote": "Pr | 0.0025",
            "source": "Table 5a"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "WMAmazon",
          "metric_name": "F1",
          "value": 0.005,
          "provenance": {
            "quote": "F1 | 0.0050",
            "source": "Table 5a"
          },
          "confidence": 0.97
        }
      ]
    },
    {
      "paper_id": "3e96d15e",
      "paper_title": "Deep Indexed Active Learning for Matching Heterogeneous Entity Representations",
      "proposed_method_name": "DIAL",
      "datasets": [
        {
          "name": "Walmart-Amazon",
          "description": "Product dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
          "task_type": [
            "entity matching"
          ],
          "processing": "Schema from DeepMatcher used; initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
          "confidence": 0.97
        },
        {
          "name": "Amazon-Google",
          "description": "Product dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
          "task_type": [
            "entity matching"
          ],
          "processing": "Schema from DeepMatcher used; initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
          "confidence": 0.97
        },
        {
          "name": "DBLP-ACM",
          "description": "Citation dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
          "task_type": [
            "entity matching"
          ],
          "processing": "Initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
          "confidence": 0.95
        },
        {
          "name": "DBLP-Scholar",
          "description": "Citation dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
          "task_type": [
            "entity matching"
          ],
          "processing": "Initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
          "confidence": 0.95
        },
        {
          "name": "Abt-Buy",
          "description": "Product dataset; textual dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
          "task_type": [
            "entity matching"
          ],
          "processing": "Initial labeled seed: 64 positive and 64 negative pairs sampled at random; CAND=20x|S| and k=20 for this dataset due to small |S|; default active learning with 10 rounds, labeling budget 128 per round",
          "confidence": 0.97
        },
        {
          "name": "MultiLingual",
          "description": "Multilingual entity matching dataset (English-German subset) from [26], originally proposed for machine translation of structured data; each element is a string in English or German (with HTML/XML tags)",
          "task_type": [
            "entity matching"
          ],
          "processing": "English-Deutsch subset; initial labeled seed: 64 positive and 64 negative pairs sampled at random; test set constructed similarly; uses multilingual BERT as base",
          "confidence": 0.93
        }
      ],
      "metrics": [
        {
          "name": "Precision",
          "description": "Fraction of predicted duplicates that are correct",
          "confidence": 0.95
        },
        {
          "name": "Recall",
          "description": "Fraction of true duplicates that are retrieved",
          "confidence": 0.95
        },
        {
          "name": "F1",
          "description": "Harmonic mean of precision and recall, measuring accuracy of duplicate detection",
          "confidence": 0.97
        }
      ],
      "baselines": [
        {
          "name": "PairedFixed",
          "description": "Non-adaptive blocking: candidate set via similarity search on pretrained TPLM embeddings; no task-specific finetuning",
          "category": "deep learning",
          "confidence": 0.92
        },
        {
          "name": "PairedAdapt",
          "description": "Embeddings from TPLM as finetuned by the matcher in paired mode; candidate set created as in PairedFixed",
          "category": "deep learning",
          "confidence": 0.92
        },
        {
          "name": "SentenceBERT",
          "description": "Finetunes TPLM and a SentenceBERT-like classifier on labeled data to obtain embeddings for similarity search; RoBERTa transformer used in this work",
          "category": "deep learning",
          "citation_number": "[34]",
          "confidence": 0.95
        },
        {
          "name": "Rules",
          "description": "Blocking based on hand-crafted rules (human-designed), applied to five benchmark datasets",
          "category": "heuristic",
          "confidence": 0.92
        },
        {
          "name": "Random Forest",
          "description": "Ensemble of 20 decision trees using learner-aware Query By Committee (QBC); strong active learning baseline for entity resolution",
          "category": "classical ML",
          "citation_number": "[40]",
          "confidence": 0.95
        },
        {
          "name": "JedAI:Schema-based",
          "description": "JedAI toolkit schema-based pipeline; similarity joins for blocking; best configuration per [47]",
          "category": "heuristic",
          "citation_number": "[47]",
          "confidence": 0.93
        },
        {
          "name": "JedAI:Schema-agnostic",
          "description": "JedAI toolkit schema-agnostic pipeline; leverages all attributes to extract overlapping blocks; best configuration per [47]",
          "category": "heuristic",
          "citation_number": "[47]",
          "confidence": 0.93
        },
        {
          "name": "PairedFixed (MultiLingual)",
          "description": "Non-adaptive blocking for MultiLingual dataset; candidate set via similarity search on pretrained multilingual BERT embeddings",
          "category": "deep learning",
          "confidence": 0.9
        },
        {
          "name": "PairedAdapt (MultiLingual)",
          "description": "Adaptive blocking for MultiLingual dataset; embeddings from multilingual BERT as finetuned by the matcher in paired mode",
          "category": "deep learning",
          "confidence": 0.9
        }
      ],
      "results": [
        {
          "dataset_name": "Walmart-Amazon",
          "metric_name": "F1",
          "value": 0.898,
          "provenance": {
            "quote": "DIAL | 94.9 | 85.2 | 89.8 |",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Amazon-Google",
          "metric_name": "F1",
          "value": 0.821,
          "provenance": {
            "quote": "DIAL | 87.4 | 77.4 | 82.1 |",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "DBLP-ACM",
          "metric_name": "F1",
          "value": 0.991,
          "provenance": {
            "quote": "DIAL | 99.6 | 98.6 | 99.1 |",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "DBLP-Scholar",
          "metric_name": "F1",
          "value": 0.968,
          "provenance": {
            "quote": "DIAL | 97.5 | 96.1 | 96.8 |",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Abt-Buy",
          "metric_name": "F1",
          "value": 0.923,
          "provenance": {
            "quote": "DIAL | 97.8 | 87.4 | 92.3 |",
            "source": "Table 2"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "MultiLingual",
          "metric_name": "F1",
          "value": 0.743,
          "provenance": {
            "quote": "DIAL | 92.2 | 62.3 | 74.3 |",
            "source": "Table 3"
          },
          "confidence": 0.93
        }
      ]
    },
    {
      "paper_id": "6ab21388",
      "paper_title": "MinoanER: Schema-Agnostic, Non-Iterative, Massively Parallel Resolution of Web Entities",
      "proposed_method_name": "MinoanER",
      "datasets": [
        {
          "name": "Restaurant",
          "description": "Contains descriptions of restaurants and their addresses from two different KBs; popular benchmark created by the Ontology Alignment Evaluation Initiative.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Rexa-DBLP",
          "description": "Contains descriptions of publications and their authors; matches between both publications and authors.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "BBCmusic-DBpedia",
          "description": "Contains descriptions of musicians, bands and their birthplaces, from BBCmusic and the BTC2012 version of DBpedia; highly heterogeneous schema and values.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.97
        },
        {
          "name": "YAGO-IMDb",
          "description": "Contains descriptions of movie-related entities (e.g., actors, directors, movies) from YAGO and IMDb; largest and most balanced KB pair.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.97
        }
      ],
      "metrics": [
        {
          "name": "Precision",
          "description": "Proportion of predicted matches that are correct.",
          "confidence": 0.98
        },
        {
          "name": "Recall",
          "description": "Proportion of ground truth matches that are correctly predicted.",
          "confidence": 0.98
        },
        {
          "name": "F1",
          "description": "Harmonic mean of precision and recall.",
          "confidence": 0.98
        }
      ],
      "baselines": [
        {
          "name": "SiGMa",
          "description": "State-of-the-art entity resolution method.",
          "category": "graph-based",
          "citation_number": "[21]",
          "confidence": 0.95
        },
        {
          "name": "LINDA",
          "description": "State-of-the-art entity resolution method.",
          "category": "heuristic",
          "citation_number": "[4]",
          "confidence": 0.9
        },
        {
          "name": "RiMOM",
          "description": "State-of-the-art entity resolution method.",
          "category": "heuristic",
          "citation_number": "[23]",
          "confidence": 0.9
        },
        {
          "name": "PARIS",
          "description": "State-of-the-art entity resolution method.",
          "category": "graph-based",
          "citation_number": "[33]",
          "confidence": 0.95
        },
        {
          "name": "BSL",
          "description": "Custom heavily fine-tuned baseline using value similarity and Unique Mapping Clustering; disregards neighbor evidence.",
          "category": "heuristic",
          "confidence": 0.92
        }
      ],
      "results": [
        {
          "dataset_name": "Restaurant",
          "metric_name": "Precision",
          "value": 1.0,
          "provenance": {
            "quote": "MinoanER | Prec. | 100",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Restaurant",
          "metric_name": "Recall",
          "value": 1.0,
          "provenance": {
            "quote": "MinoanER | Recall | 100",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Restaurant",
          "metric_name": "F1",
          "value": 1.0,
          "provenance": {
            "quote": "MinoanER | F1 | 100",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Rexa-DBLP",
          "metric_name": "Precision",
          "value": 0.9674,
          "provenance": {
            "quote": "MinoanER | Prec. | 96.74",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Rexa-DBLP",
          "metric_name": "Recall",
          "value": 0.9534,
          "provenance": {
            "quote": "MinoanER | Recall | 95.34",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Rexa-DBLP",
          "metric_name": "F1",
          "value": 0.9604,
          "provenance": {
            "quote": "MinoanER | F1 | 96.04",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "BBCmusic-DBpedia",
          "metric_name": "Precision",
          "value": 0.9144,
          "provenance": {
            "quote": "MinoanER | Prec. | 91.44",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "BBCmusic-DBpedia",
          "metric_name": "Recall",
          "value": 0.8855,
          "provenance": {
            "quote": "MinoanER | Recall | 88.55",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "BBCmusic-DBpedia",
          "metric_name": "F1",
          "value": 0.8997,
          "provenance": {
            "quote": "MinoanER | F1 | 89.97",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "YAGO-IMDb",
          "metric_name": "Precision",
          "value": 0.9102,
          "provenance": {
            "quote": "MinoanER | Prec. | 91.02",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "YAGO-IMDb",
          "metric_name": "Recall",
          "value": 0.9057,
          "provenance": {
            "quote": "MinoanER | Recall | 90.57",
            "source": "Table 3"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "YAGO-IMDb",
          "metric_name": "F1",
          "value": 0.9079,
          "provenance": {
            "quote": "MinoanER | F1 | 90.79",
            "source": "Table 3"
          },
          "confidence": 0.99
        }
      ]
    },
    {
      "paper_id": "ec4709c1",
      "paper_title": "Deep Learning for Blocking in Entity Matching: A Design Space Exploration",
      "proposed_method_name": "Autoencoder (structured/dirty), Hybrid (textual)",
      "datasets": [
        {
          "name": "Amazon-Google $_{1}$",
          "description": "Structured EM dataset; 1,363 and 3,226 tuples in Table A/B, 1,300 matches, 4 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Walmart-Amazon $_{1}$",
          "description": "Structured EM dataset; 2,554 and 22,074 tuples in Table A/B, 1,154 matches, 6 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "DBLP-Google $_{1}$",
          "description": "Structured EM dataset; 2,616 and 64,263 tuples in Table A/B, 5,347 matches, 4 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "DBLP-ACM $_{1}$",
          "description": "Structured EM dataset; 2,616 and 2,294 tuples in Table A/B, 2,224 matches, 4 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Hospital $_{1}$",
          "description": "Structured EM dataset; 1,786 and 1,786 tuples in Table A/B, 3,949 matches, 7 attributes. Private dataset.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Song-Song $_{1}$",
          "description": "Structured EM dataset; 1,000,000 and 1,000,000 tuples in Table A/B, 1,292,023 matches, 5 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Amazon-Google $_{2}$",
          "description": "Textual EM dataset (derived from Amazon-Google $_{1}$); 2 textual blob attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.96
        },
        {
          "name": "Walmart-Amazon $_{2}$",
          "description": "Textual EM dataset (derived from Walmart-Amazon $_{1}$); 2 textual blob attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.96
        },
        {
          "name": "Abt-Buy",
          "description": "Textual EM dataset; 1,081 and 1,092 tuples in Table A/B, 1,097 matches, 3 textual attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.97
        },
        {
          "name": "DBLP-ACM $_{2}$",
          "description": "Dirty EM dataset (synthetically corrupted from DBLP-ACM $_{1}$); 4 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.94
        },
        {
          "name": "Hospital $_{2}$",
          "description": "Dirty EM dataset (synthetically corrupted from Hospital $_{1}$); 7 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.94
        },
        {
          "name": "Song-Song $_{2}$",
          "description": "Dirty EM dataset (synthetically corrupted from Song-Song $_{1}$); 5 attributes",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.94
        },
        {
          "name": "Restaurants",
          "description": "Real-world dirty EM dataset; contains noise such as misspellings, missing values, incorrect entries",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.91
        },
        {
          "name": "Books",
          "description": "Real-world dirty EM dataset; contains noise such as misspellings, missing values, incorrect entries",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.91
        },
        {
          "name": "Cora",
          "description": "Real-world dirty EM dataset; contains noise such as misspellings, missing values, incorrect entries",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.91
        }
      ],
      "metrics": [
        {
          "name": "Recall",
          "description": "Fraction of true matches covered by the candidate set after blocking",
          "formulation": "|G  C| / |G|",
          "confidence": 1.0
        },
        {
          "name": "Candidate Set Size Ratio",
          "description": "Fraction of all possible pairs selected as candidates; lower is better",
          "formulation": "|C| / |A  B|",
          "confidence": 0.98
        }
      ],
      "baselines": [
        {
          "name": "RBB",
          "description": "State-of-the-art industrial non-DL solution that uses labeled data to learn a blocker",
          "category": "classical ML",
          "citation_number": null,
          "confidence": 0.95
        },
        {
          "name": "BSL",
          "description": "Blocking Scheme Learner; learns a blocker from labeled data",
          "category": "classical ML",
          "citation_number": "[53]",
          "confidence": 0.93
        },
        {
          "name": "TB",
          "description": "Token Blocking; unsupervised schema-agnostic approach",
          "category": "heuristic",
          "citation_number": "[61]",
          "confidence": 0.93
        },
        {
          "name": "AutoBlock",
          "description": "DL method that learns tuple embeddings using labeled data and LSH for retrieval",
          "category": "deep learning",
          "citation_number": "[81]",
          "confidence": 0.93
        },
        {
          "name": "DeepER",
          "description": "Existing DL solution for blocking",
          "category": "deep learning",
          "citation_number": null,
          "confidence": 0.85
        },
        {
          "name": "DeepBlock",
          "description": "Existing DL solution; marginally uses DL to improve a non-DL blocking solution",
          "category": "deep learning",
          "citation_number": null,
          "confidence": 0.83
        }
      ],
      "results": [
        {
          "dataset_name": "Amazon-Google $_{1}$",
          "metric_name": "Recall",
          "value": 0.971,
          "provenance": {
            "quote": "Amazon-Google $_{1}$ | 50 | 68.2 k | 97.1 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Walmart-Amazon $_{1}$",
          "metric_name": "Recall",
          "value": 0.922,
          "provenance": {
            "quote": "Walmart-Amazon $_{1}$ | 20 | 51.1 k | 92.2 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DBLP-Google $_{1}$",
          "metric_name": "Recall",
          "value": 0.981,
          "provenance": {
            "quote": "DBLP-Google $_{1}$ | 150 | 392.4 k | 98.1 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DBLP-ACM $_{1}$",
          "metric_name": "Recall",
          "value": 0.996,
          "provenance": {
            "quote": "DBLP-ACM $_{1}$ | 5 | 13.1 k | 99.6 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Hospital $_{1}$",
          "metric_name": "Recall",
          "value": 0.99,
          "provenance": {
            "quote": "Hospital $_{1}$ | 150 | 140k | 99.0 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Song-Song $_{1}$",
          "metric_name": "Recall",
          "value": 0.95,
          "provenance": {
            "quote": "Song-Song $_{1}$ | 50 | 50 m | 95.0 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Amazon-Google $_{2}$",
          "metric_name": "Recall",
          "value": 0.705,
          "provenance": {
            "quote": "Amazon-Google $_{2}$ | 20 | 27.3 k | 70.5 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Walmart-Amazon $_{2}$",
          "metric_name": "Recall",
          "value": 0.687,
          "provenance": {
            "quote": "Walmart-Amazon $_{2}$ | 5 | 12.8 k | 68.7 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Abt-Buy",
          "metric_name": "Recall",
          "value": 0.872,
          "provenance": {
            "quote": "Abt-Buy | 20 | 21.6 k | 87.2 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Amazon-Google $_{3}$",
          "metric_name": "Recall",
          "value": 0.971,
          "provenance": {
            "quote": "Amazon-Google $_{3}$ | 50 | 68.2 k | 97.1 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Walmart-Amazon $_{3}$",
          "metric_name": "Recall",
          "value": 0.88,
          "provenance": {
            "quote": "Walmart-Amazon $_{3}$ | 10 | 25.5 k | 88.0 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DBLP-Google $_{2}$",
          "metric_name": "Recall",
          "value": 0.981,
          "provenance": {
            "quote": "DBLP-Google $_{2}$ | 150 | 392.4 k | 98.1 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "DBLP-ACM $_{2}$",
          "metric_name": "Recall",
          "value": 0.996,
          "provenance": {
            "quote": "DBLP-ACM $_{2}$ | 5 | 13.1 k | 99.6 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Hospital $_{2}$",
          "metric_name": "Recall",
          "value": 0.89,
          "provenance": {
            "quote": "Hospital $_{2}$ | 10 | 8.3 k | 89.0 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        },
        {
          "dataset_name": "Song-Song $_{2}$",
          "metric_name": "Recall",
          "value": 0.95,
          "provenance": {
            "quote": "Song-Song $_{2}$ | 50 | 50 m | 95.0 | ...",
            "source": "Table 6"
          },
          "confidence": 0.99
        }
      ]
    },
    {
      "paper_id": "256e52ab",
      "paper_title": "ZeroEA: A Zero-Training Entity Alignment Framework via Pre-Trained Language Model",
      "proposed_method_name": "ZeroEA",
      "datasets": [
        {
          "name": "DBP15K",
          "description": "Well-recognized benchmark for entity alignment, containing three smaller subsets for cross-lingual EA, each with 15,000 aligned entity pairs.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "DWY100K",
          "description": "Comprises two subsets of a medium scale for monolingual EA, each including 100,000 aligned entity pairs and around one million triples.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.97
        },
        {
          "name": "DBP1M",
          "description": "Large EA benchmark with two cross-lingual subsets, each with over one million entities and nearly ten million triples.",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        },
        {
          "name": "SPIDER",
          "description": "Large-scale, complex, and cross-domain text-to-SQL dataset; 10,181 questions, 5,693 unique SQL queries, over 200 databases across 138 domains.",
          "task_type": [
            "qa",
            "generation"
          ],
          "confidence": 0.95
        }
      ],
      "metrics": [
        {
          "name": "Hits@1",
          "description": "Fraction of correct entities ranked at position 1.",
          "confidence": 0.95
        },
        {
          "name": "Hits@10",
          "description": "Fraction of correct entities ranked within top 10.",
          "confidence": 0.95
        },
        {
          "name": "MRR",
          "description": "Mean Reciprocal Rank; average of reciprocal ranks for correct entities.",
          "confidence": 0.95
        },
        {
          "name": "Precision",
          "description": "Proportion of predicted links that are correct.",
          "confidence": 0.9
        },
        {
          "name": "Recall",
          "description": "Proportion of true links that are recovered.",
          "confidence": 0.9
        },
        {
          "name": "F1",
          "description": "Harmonic mean of precision and recall.",
          "confidence": 0.9
        },
        {
          "name": "Exact Match (EM)",
          "description": "Measures whether the predicted SQL exactly matches the ground truth.",
          "confidence": 0.85
        },
        {
          "name": "Execution Accuracy (EX)",
          "description": "Measures whether the execution result of the predicted SQL matches the ground truth.",
          "confidence": 0.8
        }
      ],
      "baselines": [
        {
          "name": "MTransE",
          "category": "translation-based, deep learning",
          "citation_number": "[7]",
          "confidence": 0.95
        },
        {
          "name": "JAPE",
          "category": "translation-based, deep learning",
          "citation_number": "[44]",
          "confidence": 0.95
        },
        {
          "name": "BootEA",
          "category": "translation-based, deep learning",
          "citation_number": "[45]",
          "confidence": 0.95
        },
        {
          "name": "TransEdge",
          "category": "translation-based, deep learning",
          "citation_number": "[3]",
          "confidence": 0.95
        },
        {
          "name": "GCN-Align",
          "category": "GNN, deep learning",
          "citation_number": "[53]",
          "confidence": 0.95
        },
        {
          "name": "MuGNN",
          "category": "GNN, deep learning",
          "citation_number": "[6]",
          "confidence": 0.95
        },
        {
          "name": "RDGCN",
          "category": "GNN, deep learning",
          "citation_number": "[54]",
          "confidence": 0.95
        },
        {
          "name": "CEAPF",
          "category": "GNN, deep learning",
          "citation_number": "[58]",
          "confidence": 0.9
        },
        {
          "name": "MEAlormer",
          "category": "PLM-based, deep learning",
          "citation_number": "[9]",
          "confidence": 0.95
        },
        {
          "name": "BERT-INT",
          "category": "PLM-based, deep learning",
          "citation_number": "[47]",
          "confidence": 0.95
        },
        {
          "name": "SDEA",
          "category": "PLM-based, deep learning",
          "citation_number": "[65]",
          "confidence": 0.9
        },
        {
          "name": "MultiKE",
          "category": "translation-based, unsupervised",
          "citation_number": "[61]",
          "confidence": 0.9
        },
        {
          "name": "SelfKG",
          "category": "GNN, unsupervised",
          "citation_number": "[32]",
          "confidence": 0.9
        },
        {
          "name": "Graphix-base",
          "description": "Baseline text-to-SQL model using schema linking via string matching.",
          "confidence": 0.95
        },
        {
          "name": "Graphix-TransE",
          "description": "Graphix-base model with TransE-based schema linking.",
          "confidence": 0.9
        },
        {
          "name": "Graphix-GCN",
          "description": "Graphix-base model with GCN-based schema linking.",
          "confidence": 0.9
        }
      ],
      "results": [
        {
          "dataset_name": "DBP15K",
          "metric_name": "Hits@1",
          "value": 0.985,
          "provenance": {
            "quote": "ZeroEA(undir) | 0.985 | 0.993 | 0.991",
            "source": "Table 1"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DBP15K",
          "metric_name": "Hits@10",
          "value": 0.993,
          "provenance": {
            "quote": "ZeroEA(undir) | 0.985 | 0.993 | 0.991",
            "source": "Table 1"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DBP15K",
          "metric_name": "MRR",
          "value": 0.991,
          "provenance": {
            "quote": "ZeroEA(undir) | 0.985 | 0.993 | 0.991",
            "source": "Table 1"
          },
          "confidence": 0.98
        },
        {
          "dataset_name": "DWY100K",
          "metric_name": "Hits@1",
          "value": 0.998,
          "provenance": {
            "quote": "ZeroEA(undir) | 0.998 | 0.999 | 0.998",
            "source": "Table 1"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "DWY100K",
          "metric_name": "Hits@10",
          "value": 0.999,
          "provenance": {
            "quote": "ZeroEA(undir) | 0.998 | 0.999 | 0.998",
            "source": "Table 1"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "DWY100K",
          "metric_name": "MRR",
          "value": 0.998,
          "provenance": {
            "quote": "ZeroEA(undir) | 0.998 | 0.999 | 0.998",
            "source": "Table 1"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "DBP1M",
          "metric_name": "Hits@1",
          "value": 0.594,
          "provenance": {
            "quote": "On DBP1M_FR-EN, ZeroEA obtains Hit@1= 0.594 , Hit@10=0.635, and MRR =0.400",
            "source": "text"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "DBP1M",
          "metric_name": "Hits@10",
          "value": 0.635,
          "provenance": {
            "quote": "On DBP1M_FR-EN, ZeroEA obtains Hit@1= 0.594 , Hit@10=0.635, and MRR =0.400",
            "source": "text"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "DBP1M",
          "metric_name": "MRR",
          "value": 0.4,
          "provenance": {
            "quote": "On DBP1M_FR-EN, ZeroEA obtains Hit@1= 0.594 , Hit@10=0.635, and MRR =0.400",
            "source": "text"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "DBP1M",
          "metric_name": "Hits@1",
          "value": 0.616,
          "provenance": {
            "quote": "on DBP1M_DE-EN, ZeroEA obtains Hit@1= 0.616, Hit@10=0.648, and MRR =0.395",
            "source": "text"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "DBP1M",
          "metric_name": "Hits@10",
          "value": 0.648,
          "provenance": {
            "quote": "on DBP1M_DE-EN, ZeroEA obtains Hit@1= 0.616, Hit@10=0.648, and MRR =0.395",
            "source": "text"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "DBP1M",
          "metric_name": "MRR",
          "value": 0.395,
          "provenance": {
            "quote": "on DBP1M_DE-EN, ZeroEA obtains Hit@1= 0.616, Hit@10=0.648, and MRR =0.395",
            "source": "text"
          },
          "confidence": 0.9
        },
        {
          "dataset_name": "SPIDER",
          "metric_name": "Recall",
          "value": 0.902,
          "provenance": {
            "quote": "Graphix-ZeroEA | 0 . 9 0 2 | 0 . 8 8 3 | 0 . 8 9 2",
            "source": "Table 4"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "SPIDER",
          "metric_name": "Precision",
          "value": 0.883,
          "provenance": {
            "quote": "Graphix-ZeroEA | 0 . 9 0 2 | 0 . 8 8 3 | 0 . 8 9 2",
            "source": "Table 4"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "SPIDER",
          "metric_name": "F1",
          "value": 0.892,
          "provenance": {
            "quote": "Graphix-ZeroEA | 0 . 9 0 2 | 0 . 8 8 3 | 0 . 8 9 2",
            "source": "Table 4"
          },
          "confidence": 0.95
        }
      ]
    },
    {
      "paper_id": "07e4e216",
      "paper_title": "Dealing with Acronyms, Abbreviations, and Typos in Real-World Entity Matching",
      "proposed_method_name": "SMASH",
      "datasets": [
        {
          "name": "Police ROSTER",
          "description": "31,516 rows of police officer data; uses the 'Title' column with 154 distinct values (99 standard, 55 modified forms)",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Large Disease",
          "description": "405,543 rows of medical data relating to disease; each row stores a medical term with standard and modified forms; many acronyms and abbreviations but not misspellings; evaluated on a 30,000 row sample",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.98
        },
        {
          "name": "Small Disease",
          "description": "Subset of Large Disease; includes 634 disease names; pairs of standard and modified disease names",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.96
        },
        {
          "name": "Location",
          "description": "Dataset including location names (e.g., street and city names); ground truth contains 116 pairs of standard and modified names referring to the same location",
          "task_type": [
            "entity matching"
          ],
          "confidence": 0.95
        }
      ],
      "metrics": [
        {
          "name": "Precision",
          "description": "Proportion of correctly identified positive matches among all returned matches",
          "confidence": 0.95
        },
        {
          "name": "Recall",
          "description": "Proportion of correctly identified positive matches among all true matches",
          "confidence": 0.95
        },
        {
          "name": "F-score",
          "description": "Harmonic mean of precision and recall, measuring the overall match accuracy",
          "formulation": "F = 2 * (Precision * Recall) / (Precision + Recall)",
          "confidence": 0.97
        }
      ],
      "baselines": [
        {
          "name": "Levenshtein distance",
          "description": "Edit distance metric for string similarity",
          "category": "classical ML",
          "citation_number": "[4]",
          "confidence": 0.98
        },
        {
          "name": "Affine gap distance",
          "description": "Edit distance metric with different penalties for gaps",
          "category": "classical ML",
          "citation_number": "[11]",
          "confidence": 0.96
        },
        {
          "name": "Jaccard-Word",
          "description": "Tokenizes strings into sets of words and computes the Jaccard score",
          "category": "classical ML",
          "citation_number": "[36]",
          "confidence": 0.97
        },
        {
          "name": "Jaccard-NG",
          "description": "Creates n-grams (3-grams) for strings and computes Jaccard score over n-gram sets",
          "category": "classical ML",
          "citation_number": "[17]",
          "confidence": 0.97
        },
        {
          "name": "pkduck",
          "description": "Synonym rules-based approach for string matching",
          "category": "classical ML",
          "citation_number": "[30]",
          "confidence": 0.99
        },
        {
          "name": "Bipartite",
          "description": "Set similarity approach using a bipartite graph; similarity is minimal sum of edge weights divided by number of edges; edge weights evaluated with Jaccard-NG",
          "category": "graph-based",
          "citation_number": "[10, 25]",
          "confidence": 0.98
        },
        {
          "name": "ChatGPT (GPT-4.0)",
          "description": "Large language model-based approach to string matching",
          "category": "LLM",
          "citation_number": "[2]",
          "confidence": 0.98
        }
      ],
      "results": [
        {
          "dataset_name": "Large Disease",
          "metric_name": "F-score",
          "value": 0.4,
          "provenance": {
            "quote": "SMASH | 0.55 | 0.40 | (Table 2: The maximum and mean F-scores, mean for Large Disease)",
            "source": "table"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Large Disease",
          "metric_name": "F-score",
          "value": 0.55,
          "provenance": {
            "quote": "SMASH | 0.55 | 0.40 | (Table 2: The maximum and mean F-scores, max for Large Disease)",
            "source": "table"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Small Disease",
          "metric_name": "F-score",
          "value": 0.75,
          "provenance": {
            "quote": "SMASH | 0.89 | 0.75 | (Table 2: The maximum and mean F-scores, mean for Small Disease)",
            "source": "table"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Small Disease",
          "metric_name": "F-score",
          "value": 0.89,
          "provenance": {
            "quote": "SMASH | 0.89 | 0.75 | (Table 2: The maximum and mean F-scores, max for Small Disease)",
            "source": "table"
          },
          "confidence": 0.97
        },
        {
          "dataset_name": "Location",
          "metric_name": "F-score",
          "value": 0.78,
          "provenance": {
            "quote": "SMASH | 0.86 | 0.78 | (Table 2: The maximum and mean F-scores, mean for Location)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Location",
          "metric_name": "F-score",
          "value": 0.86,
          "provenance": {
            "quote": "SMASH | 0.86 | 0.78 | (Table 2: The maximum and mean F-scores, max for Location)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Police ROSTER",
          "metric_name": "F-score",
          "value": 0.64,
          "provenance": {
            "quote": "SMASH | 0.84 | 0.64 | (Table 2: The maximum and mean F-scores, mean for Police ROSTER)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Police ROSTER",
          "metric_name": "F-score",
          "value": 0.84,
          "provenance": {
            "quote": "SMASH | 0.84 | 0.64 | (Table 2: The maximum and mean F-scores, max for Police ROSTER)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Large Disease",
          "metric_name": "F-score",
          "value": 0.4,
          "provenance": {
            "quote": "SMASH | 0.27 | 0.74 | 0.4 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Large Disease",
          "metric_name": "F-score",
          "value": 0.47,
          "provenance": {
            "quote": "SMASH | 0.35 | 0.7 | 0.47 | (Table 3, =0.8)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Large Disease",
          "metric_name": "F-score",
          "value": 0.55,
          "provenance": {
            "quote": "SMASH | 0.47 | 0.66 | 0.55 | (Table 3, =0.9)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Small Disease",
          "metric_name": "F-score",
          "value": 0.74,
          "provenance": {
            "quote": "SMASH | 0.64 | 0.89 | 0.74 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Small Disease",
          "metric_name": "F-score",
          "value": 0.81,
          "provenance": {
            "quote": "SMASH | 0.74 | 0.89 | 0.81 | (Table 3, =0.8)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Small Disease",
          "metric_name": "F-score",
          "value": 0.89,
          "provenance": {
            "quote": "SMASH | 0.89 | 0.88 | 0.89 | (Table 3, =0.9)",
            "source": "table"
          },
          "confidence": 0.96
        },
        {
          "dataset_name": "Location",
          "metric_name": "F-score",
          "value": 0.76,
          "provenance": {
            "quote": "SMASH | 0.69 | 0.85 | 0.76 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "Location",
          "metric_name": "F-score",
          "value": 0.84,
          "provenance": {
            "quote": "SMASH | 0.86 | 0.83 | 0.84 | (Table 3, =0.8)",
            "source": "table"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "Location",
          "metric_name": "F-score",
          "value": 0.86,
          "provenance": {
            "quote": "SMASH | 0.94 | 0.8 | 0.86 | (Table 3, =0.9)",
            "source": "table"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "Police ROSTER",
          "metric_name": "F-score",
          "value": 0.74,
          "provenance": {
            "quote": "SMASH | 0.64 | 0.89 | 0.74 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "Police ROSTER",
          "metric_name": "F-score",
          "value": 0.81,
          "provenance": {
            "quote": "SMASH | 0.74 | 0.89 | 0.81 | (Table 3, =0.8)",
            "source": "table"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "Police ROSTER",
          "metric_name": "F-score",
          "value": 0.89,
          "provenance": {
            "quote": "SMASH | 0.89 | 0.88 | 0.89 | (Table 3, =0.9)",
            "source": "table"
          },
          "confidence": 0.95
        },
        {
          "dataset_name": "Large Disease",
          "metric_name": "Precision",
          "value": 0.27,
          "provenance": {
            "quote": "SMASH | 0.27 | 0.74 | 0.4 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.93
        },
        {
          "dataset_name": "Large Disease",
          "metric_name": "Recall",
          "value": 0.74,
          "provenance": {
            "quote": "SMASH | 0.27 | 0.74 | 0.4 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.93
        },
        {
          "dataset_name": "Small Disease",
          "metric_name": "Precision",
          "value": 0.64,
          "provenance": {
            "quote": "SMASH | 0.64 | 0.89 | 0.74 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.93
        },
        {
          "dataset_name": "Small Disease",
          "metric_name": "Recall",
          "value": 0.89,
          "provenance": {
            "quote": "SMASH | 0.64 | 0.89 | 0.74 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.93
        },
        {
          "dataset_name": "Location",
          "metric_name": "Precision",
          "value": 0.69,
          "provenance": {
            "quote": "SMASH | 0.69 | 0.85 | 0.76 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.92
        },
        {
          "dataset_name": "Location",
          "metric_name": "Recall",
          "value": 0.85,
          "provenance": {
            "quote": "SMASH | 0.69 | 0.85 | 0.76 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.92
        },
        {
          "dataset_name": "Police ROSTER",
          "metric_name": "Precision",
          "value": 0.64,
          "provenance": {
            "quote": "SMASH | 0.64 | 0.89 | 0.74 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.92
        },
        {
          "dataset_name": "Police ROSTER",
          "metric_name": "Recall",
          "value": 0.89,
          "provenance": {
            "quote": "SMASH | 0.64 | 0.89 | 0.74 | (Table 3, =0.7)",
            "source": "table"
          },
          "confidence": 0.92
        }
      ]
    }
  ],
  "canonical_datasets": [
    {
      "canonical_name": "dblp_acm",
      "aliases": [
        "DBLP-ACM",
        "DBLP-ACM $_{1}$",
        "DBLP-ACM (DA)",
        "DblpAcm",
        "DA",
        "DA-clean",
        "DA-dirty",
        "S-DA",
        "D-DA"
      ],
      "description": "Citation dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
      "task_type": [
        "entity matching"
      ],
      "processing": "Initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
      "supporting_papers": [
        "f32a10ff",
        "3e96d15e",
        "54593c94",
        "baa3b0fc",
        "ec4709c1",
        "79bc4b32",
        "10669016"
      ],
      "usage_frequency": 7
    },
    {
      "canonical_name": "dblp_scholar",
      "aliases": [
        "DBLP-Scholar",
        "DBLP-Scholar (DS)",
        "ScholarDbIp",
        "DS"
      ],
      "description": "Citation dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
      "task_type": [
        "entity matching"
      ],
      "processing": "Initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
      "supporting_papers": [
        "f32a10ff",
        "3e96d15e",
        "54593c94",
        "53cfb6e5",
        "10669016"
      ],
      "usage_frequency": 5
    },
    {
      "canonical_name": "cora",
      "aliases": [
        "Cora"
      ],
      "description": "A text-based dataset comprising duplicate references to scientific publications; structured CSV version used.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "f32a10ff",
        "b24a912c",
        "ec4709c1"
      ],
      "usage_frequency": 3
    },
    {
      "canonical_name": "fodors_zagats",
      "aliases": [
        "Fodors-Zagats",
        "FZ",
        "S-FZ"
      ],
      "description": "Restaurant matching dataset from the Magellan repository for entity resolution.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "f32a10ff",
        "54593c94",
        "baa3b0fc",
        "79bc4b32",
        "53cfb6e5"
      ],
      "usage_frequency": 5
    },
    {
      "canonical_name": "amazon_google",
      "aliases": [
        "Amazon-Google",
        "AmazonGoogle",
        "Amazon-Google (AG)",
        "AG",
        "AmazonGP",
        "Amazon-Google $_{1}$",
        "Amazon-Google $_{2}$",
        "S-AG"
      ],
      "description": "Product dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
      "task_type": [
        "entity matching"
      ],
      "processing": "Schema from DeepMatcher used; initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
      "supporting_papers": [
        "f32a10ff",
        "54593c94",
        "b24a912c",
        "3e96d15e",
        "baa3b0fc",
        "79bc4b32",
        "ec4709c1",
        "9f0c2daf",
        "53cfb6e5",
        "10669016"
      ],
      "usage_frequency": 10
    },
    {
      "canonical_name": "zomato_yelp",
      "aliases": [
        "Zomato-Yelp"
      ],
      "description": "Restaurant dataset constructed by merging Restaurants 1 and 2 from Das et al. (2016); schemas differ slightly.",
      "task_type": [
        "entity matching"
      ],
      "processing": "Null value for zip code attribute in Restaurants 1 to avoid merging errors.",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "restaurant",
      "aliases": [
        "Restaurant",
        "Restaurants"
      ],
      "description": "Contains descriptions of restaurants and their addresses from two different KBs; popular benchmark created by the Ontology Alignment Evaluation Initiative.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "6ab21388",
        "ec4709c1"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "beeradvo_ratebeer",
      "aliases": [
        "BeerAdvo-RateBeer",
        "BR",
        "S-BR",
        "Beer"
      ],
      "description": "BeerAdvo-RateBeer; beer domain, structured ER benchmark",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "baa3b0fc",
        "79bc4b32",
        "53cfb6e5"
      ],
      "usage_frequency": 3
    },
    {
      "canonical_name": "itunes_amazon",
      "aliases": [
        "IA",
        "IA-clean",
        "IA-dirty",
        "S-IA",
        "D-IA"
      ],
      "description": "clean version of iTunes-Amazon; music domain, structured ER benchmark",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "baa3b0fc",
        "79bc4b32",
        "53cfb6e5"
      ],
      "usage_frequency": 3
    },
    {
      "canonical_name": "abt_buy",
      "aliases": [
        "Abt-Buy",
        "AbtBuy",
        "Abt-Buy (AB)",
        "AB",
        "T-AB"
      ],
      "description": "Product dataset; textual dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
      "task_type": [
        "entity matching"
      ],
      "processing": "Initial labeled seed: 64 positive and 64 negative pairs sampled at random; CAND=20x|S| and k=20 for this dataset due to small |S|; default active learning with 10 rounds, labeling budget 128 per round",
      "supporting_papers": [
        "3e96d15e",
        "54593c94",
        "baa3b0fc",
        "79bc4b32",
        "53cfb6e5",
        "10669016"
      ],
      "usage_frequency": 6
    },
    {
      "canonical_name": "monitor",
      "aliases": [
        "Monitor",
        "M"
      ],
      "description": "A dataset from the Alaska benchmark for entity matching.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "alaska",
      "aliases": [
        "Alaska"
      ],
      "description": "An e-commerce product dataset collected from multiple websites.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "as",
      "aliases": [
        "AS"
      ],
      "description": "Widely recognized for Dirty ER benchmarks.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "dblp_google",
      "aliases": [
        "DBLP-Google",
        "DBLP-Google $_{1}$",
        "D-DG",
        "S-DG"
      ],
      "description": "Citation domain dataset containing bibliographic duplicates sourced from DBLP and Google Scholar.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "b24a912c",
        "ec4709c1",
        "79bc4b32"
      ],
      "usage_frequency": 3
    },
    {
      "canonical_name": "citeseer_dblp",
      "aliases": [
        "Citeseer-DBLP"
      ],
      "description": "Citation domain dataset containing bibliographic duplicates sourced from Citeseer and DBLP.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "song",
      "aliases": [
        "Song",
        "Song-Song $_{1}$",
        "Song-Song $_{2}$",
        "Songs"
      ],
      "description": "Music domain dataset including information from various platforms.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "b24a912c",
        "ec4709c1",
        "9f0c2daf"
      ],
      "usage_frequency": 3
    },
    {
      "canonical_name": "music",
      "aliases": [
        "Music"
      ],
      "description": "Music 20K dataset, used for Dirty ER benchmarks; large-scale variants up to 50K records.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "walmart_amazon",
      "aliases": [
        "Walmart-Amazon",
        "Walmart-Amazon $_{1}$",
        "WA",
        "S-WA",
        "D-WA",
        "WMAmazon"
      ],
      "description": "Product dataset; structured dataset; from DeepMatcher, ER Benchmark, and Magellan data repository",
      "task_type": [
        "entity matching"
      ],
      "processing": "Schema from DeepMatcher used; initial labeled seed: 64 positive and 64 negative pairs sampled at random; default active learning with 10 rounds, labeling budget 128 per round",
      "supporting_papers": [
        "b24a912c",
        "3e96d15e",
        "54593c94",
        "79bc4b32",
        "ec4709c1",
        "53cfb6e5",
        "9f0c2daf",
        "10669016"
      ],
      "usage_frequency": 8
    },
    {
      "canonical_name": "rexa_dblp",
      "aliases": [
        "Rexa-DBLP"
      ],
      "description": "Contains descriptions of publications and their authors; matches between both publications and authors.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "6ab21388"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bbcmusic_dbpedia",
      "aliases": [
        "BBCmusic-DBpedia"
      ],
      "description": "Contains descriptions of musicians, bands and their birthplaces, from BBCmusic and the BTC2012 version of DBpedia; highly heterogeneous schema and values.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "6ab21388"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "yago_imdb",
      "aliases": [
        "YAGO-IMDb"
      ],
      "description": "Contains descriptions of movie-related entities (e.g., actors, directors, movies) from YAGO and IMDb; largest and most balanced KB pair.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "6ab21388"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "rel_heter",
      "aliases": [
        "REL-HETER"
      ],
      "description": "Relational, heterogeneous schema entity matching dataset from Machamp",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "semi_homo",
      "aliases": [
        "SEMI-HOMO"
      ],
      "description": "Semi-structured, homogeneous schema entity matching dataset from Machamp",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "semi_heter",
      "aliases": [
        "SEMI-HETER"
      ],
      "description": "Semi-structured, heterogeneous schema entity matching dataset from Machamp",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "semi_rel",
      "aliases": [
        "SEMI-REL"
      ],
      "description": "Semi-structured and relational entity matching dataset from Machamp",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "semi_text_c",
      "aliases": [
        "SEMI-TEXT-c"
      ],
      "description": "Semi-structured and textual entity matching dataset (category) from Machamp",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "semi_text_w",
      "aliases": [
        "SEMI-TEXT-w"
      ],
      "description": "Semi-structured and textual entity matching dataset (word) from Machamp",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "rel_text",
      "aliases": [
        "REL-TEXT"
      ],
      "description": "Relational and textual entity matching dataset from Machamp",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "geo_heter",
      "aliases": [
        "GEO-HETER"
      ],
      "description": "Geospatial heterogeneous entity matching dataset",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "amazon_google_2",
      "aliases": [
        "AmazonGoogle_2",
        "Amazon-Google $_{2}$"
      ],
      "description": "Textual version derived from structured Amazon-Google dataset with 2-3 textual blob attributes.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "9f0c2daf",
        "ec4709c1"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "hospital",
      "aliases": [
        "Hospital",
        "Hospital $_{1}$",
        "Hospital $_{2}$"
      ],
      "description": "Private dataset for entity matching.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "9f0c2daf",
        "ec4709c1"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "bc",
      "aliases": [
        "BC"
      ],
      "description": "Big Citations: blocks two tables of 2.5M and 1.8M paper citations, with complete gold.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "mb",
      "aliases": [
        "MB"
      ],
      "description": "Music Brainz: blocks a table of 20M songs (against itself), with complete gold.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "wdc",
      "aliases": [
        "WDC"
      ],
      "description": "Web Data Commons: blocks a table of 26M product descriptions; lacks complete gold.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "multilingual",
      "aliases": [
        "MultiLingual"
      ],
      "description": "Multilingual entity matching dataset (English-German subset) from [26], originally proposed for machine translation of structured data; each element is a string in English or German (with HTML/XML tags)",
      "task_type": [
        "entity matching"
      ],
      "processing": "English-Deutsch subset; initial labeled seed: 64 positive and 64 negative pairs sampled at random; test set constructed similarly; uses multilingual BERT as base",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "imdb_tmdb",
      "aliases": [
        "ImdbTmdb"
      ],
      "description": "Matches movies and TV series extracted from IMDB and TheMovieDB [19]",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "imdb_tvdb",
      "aliases": [
        "ImdbTvdb"
      ],
      "description": "Matches movies and TV series extracted from IMDB and TheTVDB [19]",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "tmdb_tvdb",
      "aliases": [
        "TmdbTvdb"
      ],
      "description": "Matches movies and TV series extracted from TheMovieDB and TheTVDB [19]",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "movies",
      "aliases": [
        "Movies"
      ],
      "description": "Matches information about films extracted from imdb.com and dbpedia.org [21]",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "dbp15k",
      "aliases": [
        "DBP15K"
      ],
      "description": "Well-recognized benchmark for entity alignment, containing three smaller subsets for cross-lingual EA, each with 15,000 aligned entity pairs.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "dwy100k",
      "aliases": [
        "DWY100K"
      ],
      "description": "Comprises two subsets of a medium scale for monolingual EA, each including 100,000 aligned entity pairs and around one million triples.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "dbp1m",
      "aliases": [
        "DBP1M"
      ],
      "description": "Large EA benchmark with two cross-lingual subsets, each with over one million entities and nearly ten million triples.",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "spider",
      "aliases": [
        "SPIDER"
      ],
      "description": "Large-scale, complex, and cross-domain text-to-SQL dataset; 10,181 questions, 5,693 unique SQL queries, over 200 databases across 138 domains.",
      "task_type": [
        "qa",
        "generation"
      ],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "police_roster",
      "aliases": [
        "Police ROSTER"
      ],
      "description": "31,516 rows of police officer data; uses the 'Title' column with 154 distinct values (99 standard, 55 modified forms)",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "large_disease",
      "aliases": [
        "Large Disease"
      ],
      "description": "405,543 rows of medical data relating to disease; each row stores a medical term with standard and modified forms; many acronyms and abbreviations but not misspellings; evaluated on a 30,000 row sample",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "small_disease",
      "aliases": [
        "Small Disease"
      ],
      "description": "Subset of Large Disease; includes 634 disease names; pairs of standard and modified disease names",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "location",
      "aliases": [
        "Location"
      ],
      "description": "Dataset including location names (e.g., street and city names); ground truth contains 116 pairs of standard and modified names referring to the same location",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "books",
      "aliases": [
        "Books"
      ],
      "description": "Real-world dirty EM dataset; contains noise such as misspellings, missing values, incorrect entries",
      "task_type": [
        "entity matching"
      ],
      "supporting_papers": [
        "ec4709c1"
      ],
      "usage_frequency": 1
    }
  ],
  "canonical_metrics": [
    {
      "canonical_name": "precision",
      "aliases": [
        "Precision"
      ],
      "description": "Proportion of predicted matches that are correct.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "f32a10ff",
        "d6c37522",
        "10669016",
        "3e96d15e",
        "6ab21388",
        "256e52ab",
        "07e4e216"
      ],
      "usage_frequency": 7
    },
    {
      "canonical_name": "recall",
      "aliases": [
        "Recall"
      ],
      "description": "Proportion of ground truth matches that are correctly predicted.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "f32a10ff",
        "54593c94",
        "d6c37522",
        "9f0c2daf",
        "10669016",
        "3e96d15e",
        "6ab21388",
        "ec4709c1",
        "256e52ab",
        "07e4e216"
      ],
      "usage_frequency": 10
    },
    {
      "canonical_name": "f1",
      "aliases": [
        "F1",
        "F1 score",
        "F1-score",
        "F-score"
      ],
      "description": "Harmonic mean of precision and recall.",
      "formulation": "F1 = 2 * (precision * recall) / (precision + recall)",
      "task_scope": [],
      "supporting_papers": [
        "f32a10ff",
        "53cfb6e5",
        "79bc4b32",
        "baa3b0fc",
        "54593c94",
        "d6c37522",
        "10669016",
        "3e96d15e",
        "6ab21388",
        "256e52ab",
        "07e4e216"
      ],
      "usage_frequency": 11
    },
    {
      "canonical_name": "api_cost",
      "aliases": [
        "API Cost"
      ],
      "description": "Monetary cost for API calls to LLMs, measured in US dollars.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "53cfb6e5"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "labeling_cost",
      "aliases": [
        "Labeling Cost"
      ],
      "description": "Monetary cost for labeling entity pairs to prepare demonstrations, estimated from crowdsourcing rates.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "53cfb6e5"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "accuracy",
      "aliases": [
        "Accuracy"
      ],
      "description": "Proportion of correctly clustered records according to the ground truth clusters.",
      "formulation": "\\mathrm{ACC}=\\frac{\\text { CorrectCount }}{|\\Re|} \\quad \\text { CorrectCount }=\\sum_{X_{j} \\in \\mathbb{X}} \\sum_{x \\in X_{j}} \\mathbb{I}(\\exists y \\in M_{j}^{\\prime}, y=x)",
      "task_scope": [],
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "fp_measure",
      "aliases": [
        "FP-measure"
      ],
      "description": "Harmonic mean of purity and inverse-purity, evaluating clustering homogeneity and stability.",
      "formulation": "\\text{FP-measure}(\\mathbb{X}, \\forall)=\\frac{2}{1/\\text{purity}(\\mathbb{X}, \\forall)+1/\\text{inverse-purity}(\\mathbb{X}, \\forall)}",
      "task_scope": [],
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "candidate_set_size_ratio",
      "aliases": [
        "Candidate Set Size Ratio"
      ],
      "description": "Ratio of candidate pairs output by the blocker to all possible pairs, $CSSR=|C| /|A \\times B|$.",
      "formulation": "CSSR=|C| /|A \\times B|",
      "task_scope": [],
      "supporting_papers": [
        "9f0c2daf",
        "ec4709c1"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "hits1",
      "aliases": [
        "Hits@1"
      ],
      "description": "Fraction of correct entities ranked at position 1.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "hits10",
      "aliases": [
        "Hits@10"
      ],
      "description": "Fraction of correct entities ranked within top 10.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "mrr",
      "aliases": [
        "MRR"
      ],
      "description": "Mean Reciprocal Rank; average of reciprocal ranks for correct entities.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "exact_match_em",
      "aliases": [
        "Exact Match (EM)"
      ],
      "description": "Measures whether the predicted SQL exactly matches the ground truth.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "execution_accuracy_ex",
      "aliases": [
        "Execution Accuracy (EX)"
      ],
      "description": "Measures whether the execution result of the predicted SQL matches the ground truth.",
      "formulation": null,
      "task_scope": [],
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    }
  ],
  "canonical_baselines": [
    {
      "canonical_name": "deep learning dl",
      "aliases": [
        "Deep Learning (DL)"
      ],
      "description": "Deep learning model for entity resolution using deepmatcher library.",
      "category": "deep learning",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "deep active learning dal",
      "aliases": [
        "Deep Active Learning (DAL)"
      ],
      "description": "Active learning framework with deep models (random initialization).",
      "category": "deep learning",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "support vector machine svm",
      "aliases": [
        "Support Vector Machine (SVM)"
      ],
      "description": "Non-deep learning baseline using SVM algorithm from Magellan package.",
      "category": "classical ML",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "decision tree",
      "aliases": [
        "Decision Tree"
      ],
      "description": "Non-deep learning baseline from Magellan package.",
      "category": "classical ML",
      "supporting_papers": [
        "f32a10ff",
        "3e96d15e"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "random forest",
      "aliases": [
        "Random Forest"
      ],
      "description": "Ensemble of 20 decision trees using learner-aware Query By Committee (QBC); strong active learning baseline for entity resolution",
      "category": "classical ML",
      "supporting_papers": [
        "f32a10ff",
        "3e96d15e"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "naive bayes",
      "aliases": [
        "Naive Bayes"
      ],
      "description": "Non-deep learning baseline from Magellan package.",
      "category": "classical ML",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "logistic regression",
      "aliases": [
        "Logistic Regression"
      ],
      "description": "Non-deep learning baseline from Magellan package.",
      "category": "classical ML",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "linear regression",
      "aliases": [
        "Linear Regression"
      ],
      "description": "Non-deep learning baseline from Magellan package.",
      "category": "classical ML",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "mudgal et al 2018",
      "aliases": [
        "Mudgal et al. (2018)"
      ],
      "description": "State-of-the-art deep learning method for entity resolution.",
      "category": "deep learning",
      "supporting_papers": [
        "f32a10ff"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "ditto",
      "aliases": [
        "Ditto",
        "DITTO"
      ],
      "description": "Supervised ER model; fine-tunes a pre-trained language model for sentence-pair classification.",
      "category": "deep learning",
      "supporting_papers": [
        "53cfb6e5",
        "79bc4b32",
        "baa3b0fc",
        "54593c94",
        "d6c37522"
      ],
      "usage_frequency": 5
    },
    {
      "canonical_name": "jointbert",
      "aliases": [
        "JointBert"
      ],
      "description": "Dual-objective BERT model combining binary matching and multi-class classification for entity matching.",
      "category": "deep learning",
      "supporting_papers": [
        "53cfb6e5"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "robem",
      "aliases": [
        "RobEM"
      ],
      "description": "Robust PLM-based ER method addressing data imbalance with modifications to enhance PLMs.",
      "category": "deep learning",
      "supporting_papers": [
        "53cfb6e5"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "manualprompt",
      "aliases": [
        "ManualPrompt"
      ],
      "description": "LLM-based ER (GPT-3) using manually designed prompts and demonstrations; standard prompting.",
      "category": "LLM",
      "supporting_papers": [
        "53cfb6e5"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "dm+",
      "aliases": [
        "DM+",
        "DeepMatcher+ (DM+)"
      ],
      "description": "DeepMatcher+, a reference DL-based EM approach that does not rely on a transformer architecture.",
      "category": "deep learning",
      "supporting_papers": [
        "79bc4b32",
        "baa3b0fc"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "zeroer",
      "aliases": [
        "ZeroER"
      ],
      "description": "Unsupervised, generative ER approach using Gaussian Mixture Models",
      "category": "unsupervised",
      "supporting_papers": [
        "baa3b0fc"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "embdi",
      "aliases": [
        "EMBDI"
      ],
      "description": "Unsupervised, learns local embeddings for ER based on attribute-centric graphs",
      "category": "unsupervised",
      "supporting_papers": [
        "baa3b0fc"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "grapher",
      "aliases": [
        "GraphER"
      ],
      "description": "Supervised, integrates schematic and structural information with GNN for ER",
      "category": "graph",
      "supporting_papers": [
        "baa3b0fc"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "mca",
      "aliases": [
        "MCA"
      ],
      "description": "Supervised, uses attention mechanism in sequence-based model for ER",
      "category": "deep learning",
      "supporting_papers": [
        "baa3b0fc"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "ergan",
      "aliases": [
        "ERGAN"
      ],
      "description": "Supervised, generative adversarial network for label augmentation in ER",
      "category": "deep learning",
      "supporting_papers": [
        "baa3b0fc"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "ditto-s",
      "aliases": [
        "DITTO-S"
      ],
      "description": "DITTO using pseudo labels generated by CollaborER's ALG",
      "category": "transformer",
      "supporting_papers": [
        "baa3b0fc"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "collaborem",
      "aliases": [
        "CollaborEM"
      ],
      "description": "Unsupervised framework that constructs rule-based pseudo labels and combines graph and sentence features.",
      "category": "unsupervised",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "dtal",
      "aliases": [
        "DTAL"
      ],
      "description": "Iterative active-learning-based entity matching method allocating annotation budget to informative pairs.",
      "category": "active learning",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "ditto-full",
      "aliases": [
        "DITTO-full"
      ],
      "description": "DITTO trained with the full training data of the processed Magellan datasets.",
      "category": "deep learning",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "llama-65b",
      "aliases": [
        "LLaMA-65B"
      ],
      "description": "Large language model (65B) with 10-shot in-context learning.",
      "category": "LLM",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "gpt3-175b",
      "aliases": [
        "GPT3-175B"
      ],
      "description": "Large language model (175B parameters) with 10-shot in-context learning.",
      "category": "LLM",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "sbert",
      "aliases": [
        "SBERT"
      ],
      "description": "Pre-trained SBERT used as a blocker.",
      "category": "deep learning",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "deepblocker",
      "aliases": [
        "DeepBlocker"
      ],
      "description": "Blocker baseline for candidate generation.",
      "category": "deep learning",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "sudowoodo",
      "aliases": [
        "Sudowoodo"
      ],
      "description": "Blocker baseline for candidate generation.",
      "category": "deep learning",
      "supporting_papers": [
        "54593c94"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "booster",
      "aliases": [
        "Booster"
      ],
      "description": "LLM-based ER method employing traditional blocking and iterative partition scoring.",
      "category": "LLM",
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bq",
      "aliases": [
        "BQ"
      ],
      "description": "Batch-Questioning: Batches pairwise match questions into a single prompt for LLMs.",
      "category": "LLM",
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "crowder+llm",
      "aliases": [
        "CrowdER+LLM"
      ],
      "description": "Clustering-based design that filters irrelevant pairs and uses LLM to cluster ambiguous cases.",
      "category": "LLM",
      "supporting_papers": [
        "b24a912c"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "deepmatcher",
      "aliases": [
        "DeepMatcher"
      ],
      "description": "Entity matching framework using RNNs to aggregate attribute values",
      "category": "deep learning",
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bert",
      "aliases": [
        "BERT"
      ],
      "description": "Fine-tuned for entity matching as a sequence pair classification task",
      "category": "deep learning",
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "sentencebert",
      "aliases": [
        "SentenceBERT"
      ],
      "description": "Finetunes TPLM and a SentenceBERT-like classifier on labeled data to obtain embeddings for similarity search; RoBERTa transformer used in this work",
      "category": "deep learning",
      "supporting_papers": [
        "d6c37522",
        "3e96d15e"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "dader",
      "aliases": [
        "DADER"
      ],
      "description": "Transfer learning-based EM framework via domain adaptation",
      "category": "deep learning",
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "rotom",
      "aliases": [
        "Rotom"
      ],
      "description": "Meta-learning framework for data selection/weighting to better fine-tune LMs",
      "category": "deep learning",
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "tdmatch",
      "aliases": [
        "TDmatch"
      ],
      "description": "Unsupervised approach using graph creation and random walk for structured/text data",
      "category": "graph-based, unsupervised",
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "tdmatch*",
      "aliases": [
        "TDmatch*"
      ],
      "description": "TDmatch embeddings with an MLP classifier in supervised setting",
      "category": "deep learning",
      "supporting_papers": [
        "d6c37522"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "autoencoder",
      "aliases": [
        "Autoencoder"
      ],
      "description": "Deep learning (DL) based blocker; one of the two best DL blockers.",
      "category": "deep learning",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "hybrid",
      "aliases": [
        "Hybrid"
      ],
      "description": "Deep learning based blocker; one of the two best DL blockers.",
      "category": "deep learning",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "uniondlrbb",
      "aliases": [
        "Union(DL,RBB)"
      ],
      "description": "Combination of the best DL blocker and RBB, a SOTA industrial blocker.",
      "category": "deep learning, industrial",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "pbw",
      "aliases": [
        "PBW"
      ],
      "description": "SOTA hash blocker from JedAI open-source platform.",
      "category": "hashing",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "dbw",
      "aliases": [
        "DBW"
      ],
      "description": "SOTA hash blocker from JedAI open-source platform.",
      "category": "hashing",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "jd",
      "aliases": [
        "JD"
      ],
      "description": "SOTA hash blocker from JedAI open-source platform.",
      "category": "hashing",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "knn-cosine",
      "aliases": [
        "kNN-cosine"
      ],
      "description": "kNN blocker using cosine similarity over 5-gram tokenization.",
      "category": "heuristic",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "knn-jaccard",
      "aliases": [
        "kNN-jaccard"
      ],
      "description": "kNN blocker using Jaccard similarity over 3-gram and 5-gram tokenization.",
      "category": "heuristic",
      "supporting_papers": [
        "9f0c2daf"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bci",
      "aliases": [
        "BCI"
      ],
      "description": "Binary classifier for weight-based supervised meta-blocking",
      "category": "classical ML",
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "cep",
      "aliases": [
        "CEP"
      ],
      "description": "Cardinality-based pruning algorithm",
      "category": "heuristic",
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "cnp",
      "aliases": [
        "CNP"
      ],
      "description": "Cardinality-based pruning algorithm",
      "category": "heuristic",
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "supervised meta-blocking",
      "aliases": [
        "Supervised Meta-blocking"
      ],
      "description": "Original supervised meta-blocking framework using BCI and CNP with the feature set proposed in [25]",
      "category": "classical ML",
      "supporting_papers": [
        "10669016"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "pairedfixed",
      "aliases": [
        "PairedFixed"
      ],
      "description": "Non-adaptive blocking: candidate set via similarity search on pretrained TPLM embeddings; no task-specific finetuning",
      "category": "deep learning",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "pairedadapt",
      "aliases": [
        "PairedAdapt"
      ],
      "description": "Embeddings from TPLM as finetuned by the matcher in paired mode; candidate set created as in PairedFixed",
      "category": "deep learning",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "rules",
      "aliases": [
        "Rules"
      ],
      "description": "Blocking based on hand-crafted rules (human-designed), applied to five benchmark datasets",
      "category": "heuristic",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "jedaischema-based",
      "aliases": [
        "JedAI:Schema-based"
      ],
      "description": "JedAI toolkit schema-based pipeline; similarity joins for blocking; best configuration per [47]",
      "category": "heuristic",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "jedaischema-agnostic",
      "aliases": [
        "JedAI:Schema-agnostic"
      ],
      "description": "JedAI toolkit schema-agnostic pipeline; leverages all attributes to extract overlapping blocks; best configuration per [47]",
      "category": "heuristic",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "pairedfixed multilingual",
      "aliases": [
        "PairedFixed (MultiLingual)"
      ],
      "description": "Non-adaptive blocking for MultiLingual dataset; candidate set via similarity search on pretrained multilingual BERT embeddings",
      "category": "deep learning",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "pairedadapt multilingual",
      "aliases": [
        "PairedAdapt (MultiLingual)"
      ],
      "description": "Adaptive blocking for MultiLingual dataset; embeddings from multilingual BERT as finetuned by the matcher in paired mode",
      "category": "deep learning",
      "supporting_papers": [
        "3e96d15e"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "sigma",
      "aliases": [
        "SiGMa"
      ],
      "description": "State-of-the-art entity resolution method.",
      "category": "graph-based",
      "supporting_papers": [
        "6ab21388"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "linda",
      "aliases": [
        "LINDA"
      ],
      "description": "State-of-the-art entity resolution method.",
      "category": "heuristic",
      "supporting_papers": [
        "6ab21388"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "rimom",
      "aliases": [
        "RiMOM"
      ],
      "description": "State-of-the-art entity resolution method.",
      "category": "heuristic",
      "supporting_papers": [
        "6ab21388"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "paris",
      "aliases": [
        "PARIS"
      ],
      "description": "State-of-the-art entity resolution method.",
      "category": "graph-based",
      "supporting_papers": [
        "6ab21388"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bsl",
      "aliases": [
        "BSL"
      ],
      "description": "Blocking Scheme Learner; learns a blocker from labeled data",
      "category": "classical ML",
      "supporting_papers": [
        "6ab21388",
        "ec4709c1"
      ],
      "usage_frequency": 2
    },
    {
      "canonical_name": "rbb",
      "aliases": [
        "RBB"
      ],
      "description": "State-of-the-art industrial non-DL solution that uses labeled data to learn a blocker",
      "category": "classical ML",
      "supporting_papers": [
        "ec4709c1"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "tb",
      "aliases": [
        "TB"
      ],
      "description": "Token Blocking; unsupervised schema-agnostic approach",
      "category": "heuristic",
      "supporting_papers": [
        "ec4709c1"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "autoblock",
      "aliases": [
        "AutoBlock"
      ],
      "description": "DL method that learns tuple embeddings using labeled data and LSH for retrieval",
      "category": "deep learning",
      "supporting_papers": [
        "ec4709c1"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "deeper",
      "aliases": [
        "DeepER"
      ],
      "description": "Existing DL solution for blocking",
      "category": "deep learning",
      "supporting_papers": [
        "ec4709c1"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "deepblock",
      "aliases": [
        "DeepBlock"
      ],
      "description": "Existing DL solution; marginally uses DL to improve a non-DL blocking solution",
      "category": "deep learning",
      "supporting_papers": [
        "ec4709c1"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "mtranse",
      "aliases": [
        "MTransE"
      ],
      "description": "",
      "category": "translation-based, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "jape",
      "aliases": [
        "JAPE"
      ],
      "description": "",
      "category": "translation-based, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bootea",
      "aliases": [
        "BootEA"
      ],
      "description": "",
      "category": "translation-based, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "transedge",
      "aliases": [
        "TransEdge"
      ],
      "description": "",
      "category": "translation-based, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "gcn-align",
      "aliases": [
        "GCN-Align"
      ],
      "description": "",
      "category": "GNN, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "mugnn",
      "aliases": [
        "MuGNN"
      ],
      "description": "",
      "category": "GNN, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "rdgcn",
      "aliases": [
        "RDGCN"
      ],
      "description": "",
      "category": "GNN, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "ceapf",
      "aliases": [
        "CEAPF"
      ],
      "description": "",
      "category": "GNN, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "mealormer",
      "aliases": [
        "MEAlormer"
      ],
      "description": "",
      "category": "PLM-based, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bert-int",
      "aliases": [
        "BERT-INT"
      ],
      "description": "",
      "category": "PLM-based, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "sdea",
      "aliases": [
        "SDEA"
      ],
      "description": "",
      "category": "PLM-based, deep learning",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "multike",
      "aliases": [
        "MultiKE"
      ],
      "description": "",
      "category": "translation-based, unsupervised",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "selfkg",
      "aliases": [
        "SelfKG"
      ],
      "description": "",
      "category": "GNN, unsupervised",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "graphix-base",
      "aliases": [
        "Graphix-base"
      ],
      "description": "Baseline text-to-SQL model using schema linking via string matching.",
      "category": "",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "graphix-transe",
      "aliases": [
        "Graphix-TransE"
      ],
      "description": "Graphix-base model with TransE-based schema linking.",
      "category": "",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "graphix-gcn",
      "aliases": [
        "Graphix-GCN"
      ],
      "description": "Graphix-base model with GCN-based schema linking.",
      "category": "",
      "supporting_papers": [
        "256e52ab"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "levenshtein distance",
      "aliases": [
        "Levenshtein distance"
      ],
      "description": "Edit distance metric for string similarity",
      "category": "classical ML",
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "affine gap distance",
      "aliases": [
        "Affine gap distance"
      ],
      "description": "Edit distance metric with different penalties for gaps",
      "category": "classical ML",
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "jaccard-word",
      "aliases": [
        "Jaccard-Word"
      ],
      "description": "Tokenizes strings into sets of words and computes the Jaccard score",
      "category": "classical ML",
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "jaccard-ng",
      "aliases": [
        "Jaccard-NG"
      ],
      "description": "Creates n-grams (3-grams) for strings and computes Jaccard score over n-gram sets",
      "category": "classical ML",
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "pkduck",
      "aliases": [
        "pkduck"
      ],
      "description": "Synonym rules-based approach for string matching",
      "category": "classical ML",
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "bipartite",
      "aliases": [
        "Bipartite"
      ],
      "description": "Set similarity approach using a bipartite graph; similarity is minimal sum of edge weights divided by number of edges; edge weights evaluated with Jaccard-NG",
      "category": "graph-based",
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    },
    {
      "canonical_name": "chatgpt gpt-4.0",
      "aliases": [
        "ChatGPT (GPT-4.0)"
      ],
      "description": "Large language model-based approach to string matching",
      "category": "LLM",
      "supporting_papers": [
        "07e4e216"
      ],
      "usage_frequency": 1
    }
  ],
  "summary_statistics": {
    "avg_datasets_per_paper": 1.0,
    "avg_metrics_per_paper": 1.0,
    "avg_baselines_per_paper": 1.0,
    "unique_datasets": 48,
    "unique_metrics": 13,
    "unique_baselines": 90
  }
}